"""
STT ì²˜ë¦¬ ê´€ë ¨ í•¸ë“¤ëŸ¬
ìŒì„± íŒŒì¼ STT ì²˜ë¦¬ ë° ê´€ë ¨ ê¸°ëŠ¥
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, Depends
from typing import Optional, Dict, List
import uuid
import os
import tempfile
import whisper
from datetime import datetime
import logging

from models import STTResponse, ERPData
from domain_manager import domain_manager
from postprocessor import comprehensive_postprocess
from gpt_extractor import ERPExtractor
from supabase_client import get_supabase_manager

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/api", tags=["STT"])

# ì „ì—­ ë³€ìˆ˜
whisper_model = None
erp_extractor = None
cached_whisper_models = {}
AUDIO_DIRECTORY = "src_record"
SUPPORTED_AUDIO_EXTENSIONS = ['.mp3', '.wav', '.m4a', '.flac']

def initialize_models():
    """ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ (ì•ˆì „í•œ ë‹¨ê³„ë³„ ì´ˆê¸°í™”)"""
    global whisper_model, erp_extractor
    
    logger.info("ğŸš€ STT ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
    
    # 1. Whisper ëª¨ë¸ ì´ˆê¸°í™”
    logger.info("1ï¸âƒ£ Whisper ëª¨ë¸ë“¤ ë¡œë”© ì¤‘... (ì¸í„°ë„· ì—°ê²° í•„ìš”)")
    try:
        # ê¸°ë³¸ ëª¨ë¸ë“¤ ë¡œë”©
        model_names = ["base", "small", "medium", "large"]
        for model_name in model_names:
            logger.info(f"   - {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            try:
                model = whisper.load_model(model_name)
                cached_whisper_models[model_name] = model
                logger.info(f"   âœ… {model_name} ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"   âŒ {model_name} ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                return False
        
        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        whisper_model = cached_whisper_models.get("base")
        logger.info(f"âœ… Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ - ê¸°ë³¸ ëª¨ë¸: {list(cached_whisper_models.keys())}")
        
    except Exception as e:
        logger.error(f"âŒ Whisper ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    # 2. ERP Extractor ì´ˆê¸°í™”
    logger.info("2ï¸âƒ£ ERP Extractor ì´ˆê¸°í™” ì¤‘...")
    try:
        erp_extractor = ERPExtractor()
        logger.info("âœ… ERP Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ERP Extractor ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    logger.info("ğŸ‰ STT ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!")
    return True

def get_whisper_model(model_name: str = "small"):
    """ìš”ì²­ëœ Whisper ëª¨ë¸ì„ ë°˜í™˜"""
    if model_name in cached_whisper_models:
        return cached_whisper_models[model_name]
    elif cached_whisper_models:
        # ìš”ì²­ëœ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ ë°˜í™˜
        default_model = list(cached_whisper_models.values())[0]
        logger.warning(f"ìš”ì²­ëœ ëª¨ë¸ '{model_name}'ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return default_model
    else:
        raise HTTPException(status_code=500, detail="Whisper ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def clear_model_cache():
    """ëª¨ë¸ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"""
    global whisper_model, cached_whisper_models
    logger.info("ëª¨ë¸ ìºì‹œ ì •ë¦¬ ì¤‘...")
    cached_whisper_models.clear()
    whisper_model = None
    logger.info("ëª¨ë¸ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

def clear_whisper_file_cache():
    """Whisper íŒŒì¼ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"""
    import shutil
    import os
    
    # Whisper ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œë“¤
    cache_paths = [
        os.path.expanduser("~/.cache/whisper"),
        os.path.expanduser("~/AppData/Local/whisper"),
        os.path.expanduser("~/AppData/Roaming/whisper")
    ]
    
    logger.info("Whisper íŒŒì¼ ìºì‹œ ì •ë¦¬ ì¤‘...")
    
    for cache_path in cache_paths:
        if os.path.exists(cache_path):
            try:
                shutil.rmtree(cache_path)
                logger.info(f"Whisper ìºì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ: {cache_path}")
            except Exception as e:
                logger.warning(f"Whisper ìºì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {cache_path}, ì˜¤ë¥˜: {e}")
    
    logger.info("Whisper íŒŒì¼ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

def _create_simple_summary(transcript: str, erp_data: dict) -> str:
    """
    íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ ìš”ì•½ ìƒì„± (ê³ ê°ì„¼í„° í†µí™” íŠ¹í™”)
    """
    try:
        import re
        
        # ERP ë°ì´í„°ì—ì„œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
        as_support = erp_data.get("AS ë° ì§€ì›", "ì •ë³´ ì—†ìŒ")
        request_org = erp_data.get("ìš”ì²­ê¸°ê´€", "ì •ë³´ ì—†ìŒ")
        request_type = erp_data.get("ìš”ì²­ìœ í˜•", "ì •ë³´ ì—†ìŒ")
        location = erp_data.get("ì‘ì—…êµ­ì†Œ", "ì •ë³´ ì—†ìŒ")
        
        # 1. í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ (íŒ¨í„´ ë§¤ì¹­)
        key_sentences = _extract_key_sentences(transcript)
        
        # 2. ìš”ì²­ ìœ í˜• ë¶„ì„
        request_analysis = _analyze_request_type(transcript)
        
        # 3. ë¬¸ì œ ìƒí™© ì¶”ì¶œ
        problem_info = _extract_problem_info(transcript)
        
        # 4. ì‹œê°„/ì¥ì†Œ ì •ë³´ ì¶”ì¶œ
        time_location = _extract_time_location(transcript)
        
        # 5. ìš”ì•½ ìƒì„±
        summary = f"""[ìš”ì•½] {request_org} {as_support} ìš”ì²­
[ìœ í˜•] {request_type} | {request_analysis}
[ìœ„ì¹˜] {location} | {time_location}
[ë¬¸ì œ] {problem_info}
[í•µì‹¬] {key_sentences}"""
        
        logger.info("íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ ìš”ì•½ ìƒì„± ì™„ë£Œ")
        return summary
        
    except Exception as e:
        logger.warning(f"íŒ¨í„´ ë§¤ì¹­ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return f"[ìš”ì•½] ìš”ì²­ ë‚´ìš©: {transcript[:100]}..."

def _extract_key_sentences(transcript: str) -> str:
    """í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ (íŒ¨í„´ ë§¤ì¹­)"""
    import re
    
    # ê³ ê° ìš”ì²­ ê´€ë ¨ íŒ¨í„´
    request_patterns = [
        r'[ê°€-í£]*[ê°€-í£]*(?:ë¬¸ì œ|ì¥ì• |ì˜¤ë¥˜|ì•ˆë¨|ì•ˆë¼|ì•ˆë˜|ê³ ì¥|ì´ìƒ)[ê°€-í£]*',
        r'[ê°€-í£]*[ê°€-í£]*(?:ìš”ì²­|ë¶€íƒ|í•´ì£¼ì„¸ìš”|ë„ì™€ì£¼ì„¸ìš”|ì§€ì›)[ê°€-í£]*',
        r'[ê°€-í£]*[ê°€-í£]*(?:ê¸‰í•¨|ê¸‰í•´|ë¹¨ë¦¬|ì˜¤ëŠ˜|ë‚´ì¼)[ê°€-í£]*'
    ]
    
    sentences = transcript.split('.')
    key_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) < 10:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
            continue
            
        for pattern in request_patterns:
            if re.search(pattern, sentence):
                key_sentences.append(sentence)
                break
    
    # ìµœëŒ€ 3ê°œ ë¬¸ì¥ë§Œ ì„ íƒ
    return ' | '.join(key_sentences[:3]) if key_sentences else "í•µì‹¬ ë¬¸ì¥ ì—†ìŒ"

def _analyze_request_type(transcript: str) -> str:
    """ìš”ì²­ ìœ í˜• ë¶„ì„"""
    import re
    
    # ì¥ì•  ê´€ë ¨ íŒ¨í„´
    if re.search(r'(?:ì¥ì• |ì˜¤ë¥˜|ê³ ì¥|ì´ìƒ|ì•ˆë¨|ì•ˆë¼)', transcript):
        return "ì¥ì• ì‹ ê³ "
    
    # ê¸°ìˆ ì§€ì› ê´€ë ¨ íŒ¨í„´
    if re.search(r'(?:ì§€ì›|ë„ì›€|í•´ê²°|ìˆ˜ë¦¬|ì ê²€)', transcript):
        return "ê¸°ìˆ ì§€ì›"
    
    # ë¬¸ì˜ ê´€ë ¨ íŒ¨í„´
    if re.search(r'(?:ë¬¸ì˜|ì§ˆë¬¸|í™•ì¸|ì•Œë ¤ì£¼ì„¸ìš”)', transcript):
        return "ë¬¸ì˜ì‚¬í•­"
    
    # ê¸´ê¸‰ ê´€ë ¨ íŒ¨í„´
    if re.search(r'(?:ê¸‰í•¨|ê¸‰í•´|ë¹¨ë¦¬|ì¦‰ì‹œ)', transcript):
        return "ê¸´ê¸‰ìš”ì²­"
    
    return "ì¼ë°˜ìš”ì²­"

def _extract_problem_info(transcript: str) -> str:
    """ë¬¸ì œ ìƒí™© ì •ë³´ ì¶”ì¶œ"""
    import re
    
    # ì¥ë¹„/ì‹œìŠ¤í…œ ê´€ë ¨ íŒ¨í„´
    equipment_patterns = [
        r'(?:MSPP|1646SMC|ê³µìœ ê¸°|ë¼ìš°í„°|ìŠ¤ìœ„ì¹˜|ì„œë²„)',
        r'(?:ì¥ë¹„|ì‹œìŠ¤í…œ|ë„¤íŠ¸ì›Œí¬|íšŒì„ |ì¸í„°ë„·)'
    ]
    
    # ë¬¸ì œ ìƒí™© íŒ¨í„´
    problem_patterns = [
        r'(?:êº¼ì ¸|êº¼ì§|ì•ˆë¨|ì•ˆë¼|ê³ ì¥|ì´ìƒ)',
        r'(?:ëŠë ¤|ëŠë¦¼|ëŠì–´|ëŠê¹€|ë¶ˆì•ˆì •)'
    ]
    
    problems = []
    
    for eq_pattern in equipment_patterns:
        for prob_pattern in problem_patterns:
            pattern = f'{eq_pattern}.*?{prob_pattern}|{prob_pattern}.*?{eq_pattern}'
            matches = re.findall(pattern, transcript)
            problems.extend(matches)
    
    return ' | '.join(problems[:2]) if problems else "ë¬¸ì œ ì •ë³´ ì—†ìŒ"

def _extract_time_location(transcript: str) -> str:
    """ì‹œê°„/ì¥ì†Œ ì •ë³´ ì¶”ì¶œ"""
    import re
    
    # ì‹œê°„ ê´€ë ¨ íŒ¨í„´
    time_patterns = [
        r'(?:ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ)',
        r'(?:ì˜¤ì „|ì˜¤í›„|ì €ë…)',
        r'(?:[0-9]{1,2}ì‹œ|[0-9]{1,2}:00)'
    ]
    
    # ì¥ì†Œ ê´€ë ¨ íŒ¨í„´
    location_patterns = [
        r'(?:[0-9]+ì¸µ|[0-9]+F)',
        r'(?:ì„œìš¸|ë¶€ì‚°|ëŒ€ì „|ëŒ€êµ¬|ê´‘ì£¼|ì¸ì²œ)',
        r'(?:ì‚¬ë¬´ì‹¤|íšŒì˜ì‹¤|ì„œë²„ì‹¤|ê¸°ê³„ì‹¤)'
    ]
    
    time_info = []
    location_info = []
    
    for pattern in time_patterns:
        matches = re.findall(pattern, transcript)
        time_info.extend(matches)
    
    for pattern in location_patterns:
        matches = re.findall(pattern, transcript)
        location_info.extend(matches)
    
    time_str = ' | '.join(time_info[:2]) if time_info else ""
    location_str = ' | '.join(location_info[:2]) if location_info else ""
    
    return f"{time_str} {location_str}".strip()

def get_erp_extractor():
    """ERP Extractorë¥¼ ë°˜í™˜"""
    global erp_extractor
    if erp_extractor is None:
        logger.warning("ERP Extractorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return erp_extractor

@router.post("/stt-process", response_model=STTResponse)
async def process_audio_file(
    file: UploadFile = File(..., description="ì—…ë¡œë“œí•  ìŒì„± íŒŒì¼"),
    model_name: str = "base",
    language: Optional[str] = None,
    enable_diarization: bool = True,
    extract_erp: bool = True,
    save_to_db: bool = True,
    whisper_model=Depends(get_whisper_model),
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager)
):
    start_time = datetime.now()
    file_id = f"stt_{uuid.uuid4().hex[:8]}"
    if language == 'auto':
        language = None
    
    try:
        logger.info(f"STT ì²˜ë¦¬ ì‹œì‘ - File ID: {file_id}, íŒŒì¼ëª…: {file.filename}")
        logger.info(f"ìš”ì²­ ì˜µì…˜ - model_name={model_name}, language={language}, extract_erp={extract_erp}, save_to_db={save_to_db}, enable_diarization={enable_diarization}")
        
        # íŒŒì¼ í™•ì¥ì í™•ì¸
        allowed_extensions = ['.mp3', '.wav', '.m4a', '.flac']
        file_extension = os.path.splitext(file.filename)[1].lower()
        if file_extension not in allowed_extensions:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}")
        
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            # Whisper STT ì²˜ë¦¬
            logger.info(f"Whisper STT ì²˜ë¦¬ ì¤‘ - ëª¨ë¸: {model_name}")
            
            # ëª¨ë¸ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
            current_model = get_whisper_model(model_name)
            
            # STT ì‹¤í–‰
            result = current_model.transcribe(
                temp_file_path, 
                language=language,
                beam_size=1,
                verbose=True,
                no_speech_threshold=0.6,  # ìŒì„± ì—†ëŠ” êµ¬ê°„ ê°ì§€ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                logprob_threshold=-1.0,   # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’ (í’ˆì§ˆ í–¥ìƒ)
                compression_ratio_threshold=2.4,  # ì••ì¶• ë¹„ìœ¨ ì„ê³„ê°’ (íš¨ìœ¨ì„± í–¥ìƒ)
                condition_on_previous_text=True,  # ì´ì „ í…ìŠ¤íŠ¸ ì¡°ê±´í™” (ì •í™•ë„ í–¥ìƒ)
                word_timestamps=False  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)
            )
            
            # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì²˜ë¦¬ (ë‹¨ìˆœí™”: ì›ë³¸ + í›„ì²˜ë¦¬)
            segments = []
            original_segments = []  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë³´ì¡´
            
            # ë„ë©”ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (í†µí•© í›„ì²˜ë¦¬ìš©)
            domain_data = None
            if extract_erp and erp_extractor is not None:
                try:
                    domain_data = domain_manager.get_domain_data()
                except Exception as e:
                    logger.warning(f"ë„ë©”ì¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            for i, segment in enumerate(result.get("segments", [])):
                original_text = segment["text"].strip()
                
                # í†µí•© í›„ì²˜ë¦¬ ì ìš© (ìŒì„± ì •ê·œí™” + ìœ ì‚¬ë„ ë§¤í•‘)
                processed_text = comprehensive_postprocess(original_text, domain_data)
                
                # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ë¡œê·¸ ì¶œë ¥
                logger.info(f"ì„¸ê·¸ë¨¼íŠ¸ {i+1}: ì›ë³¸='{original_text}' â†’ í›„ì²˜ë¦¬='{processed_text}'")
                
                # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
                original_segment = {
                    "id": i,
                    "text": original_text,
                    "start": segment["start"],
                    "end": segment["end"],
                    "speaker": f"Speaker_{i % 2}"
                }
                original_segments.append(original_segment)
                
                # í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ (ë©”ì¸ ì‚¬ìš©)
                segment_data = {
                    "id": i,
                    "text": processed_text,
                    "start": segment["start"],
                    "end": segment["end"],
                    "speaker": f"Speaker_{i % 2}"
                }
                segments.append(segment_data)
            
            # ERP ë°ì´í„° ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ê°œì„ )
            erp_data = None
            if extract_erp and segments and erp_extractor is not None:
                try:
                    logger.info("ERP ë°ì´í„° ì¶”ì¶œ ì¤‘... (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                    erp_dict = erp_extractor.extract_from_segments(segments, filename=file.filename)
                    logger.info(f"ì¶”ì¶œëœ ERP ë”•ì…”ë„ˆë¦¬: {erp_dict}")
                    try:
                        erp_data = ERPData(**erp_dict)
                        logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
                    except Exception as validation_error:
                        logger.error(f"ERPData ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {validation_error}")
                        logger.error(f"ë¬¸ì œê°€ ëœ ë°ì´í„°: {erp_dict}")
                        logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                        erp_data = None
                except TimeoutError as e:
                    logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ: {e}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                except Exception as e:
                    logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            elif extract_erp and erp_extractor is None:
                logger.info("âš ï¸ ERP Extractorê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ìƒì„± (ì›ë³¸ + í›„ì²˜ë¦¬)
            original_text = result["text"]
            processed_text = comprehensive_postprocess(original_text, domain_data)
            
            # Supabaseì— STT ì„¸ì…˜ ì €ì¥ (í•­ìƒ ì €ì¥)
            session_id = None
            extraction_id = None
            
            if supabase_mgr:
                try:
                    logger.info("Supabaseì— STT ê²°ê³¼ ì €ì¥ ì¤‘...")
                    session = supabase_mgr.create_stt_session(
                        file_name=file.filename,
                        file_id=file_id,
                        model_name=model_name,
                        language=language
                    )
                    session_id = session['id']
                    supabase_mgr.update_stt_session(
                        session_id=session_id,
                        transcript=processed_text,
                        original_transcript=original_text,
                        segments=segments,
                        original_segments=original_segments,
                        processing_time=processing_time,
                        status="completed"
                    )
                    if erp_data:
                        erp_dict = erp_data.dict(by_alias=True)
                        
                        # ì „ì‚¬ ìš”ì•½ í†µí•© (ì„±ëŠ¥ ìµœì í™” - ê°„ë‹¨í•œ ìš”ì•½)
                        try:
                            # ê°„ë‹¨í•œ ìš”ì•½ ìƒì„± (GPT API í˜¸ì¶œ ì—†ì´)
                            simple_summary = _create_simple_summary(processed_text, erp_dict)
                            erp_dict["ìš”ì²­ ì‚¬í•­"] = simple_summary
                            logger.info("ê°„ë‹¨í•œ ìš”ì•½ ê¸°ë°˜ ìš”ì²­ì‚¬í•­ ìƒì„± ì™„ë£Œ")
                        except Exception as e:
                            logger.warning(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
                            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ì„¤ì •
                            erp_dict["ìš”ì²­ ì‚¬í•­"] = "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
                        
                        extraction = supabase_mgr.save_erp_extraction(
                            session_id=session_id,
                            erp_data=erp_dict
                        )
                        extraction_id = extraction['id']
                        logger.info(f"ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
                    if save_to_db and extraction_id:
                        try:
                            logger.info("ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ ì¤‘...")
                            erp_id = f"auto{uuid.uuid4().hex[:8]}"
                            erp_response_data = {
                                "status": "success",
                                "erp_id": erp_id,
                                "message": "STT ì²˜ë¦¬ ì¤‘ ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
                            }
                            supabase_mgr.save_erp_register_log(
                                extraction_id=extraction_id,
                                erp_id=erp_id,
                                status="success",
                                response_data=erp_response_data
                            )
                            logger.info(f"ERP ìë™ ë“±ë¡ ì™„ë£Œ - ERP ID: {erp_id}, ì¶”ì¶œ ID: {extraction_id}")
                        except Exception as e:
                            logger.warning(f"ERP ìë™ ë“±ë¡ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                            try:
                                supabase_mgr.save_erp_register_log(
                                    extraction_id=extraction_id,
                                    erp_id="",
                                    status="failed",
                                    response_data={"error": str(e)}
                                )
                            except:
                                pass
                    logger.info(f"Supabase ì €ì¥ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}")
                except Exception as e:
                    logger.warning(f"Supabase ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            
            response = STTResponse(
                status="success",
                transcript=processed_text,
                segments=segments,
                erp_data=erp_data,
                processing_time=processing_time,
                file_id=file_id,
                original_transcript=original_text,
                original_segments=original_segments
            )
            if session_id:
                response.session_id = session_id
            if extraction_id:
                response.extraction_id = extraction_id
            logger.info(f"STT ì²˜ë¦¬ ì™„ë£Œ - File ID: {file_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            return response
        finally:
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"STT ì²˜ë¦¬ ì‹¤íŒ¨ - File ID: {file_id}: {e}")
        raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.post("/stt-process-file", response_model=STTResponse)
async def process_audio_file_from_directory(
    filename: str,
    model_name: str = "base",
    language: Optional[str] = None,
    enable_diarization: bool = True,
    extract_erp: bool = True,
    save_to_db: bool = True,
    whisper_model=Depends(get_whisper_model),
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager)
):
    start_time = datetime.now()
    file_id = f"stt_{uuid.uuid4().hex[:8]}"
    if language == 'auto':
        language = None
    
    try:
        logger.info(f"ìš”ì²­ ì˜µì…˜ - model_name={model_name}, language={language}, extract_erp={extract_erp}, save_to_db={save_to_db}, enable_diarization={enable_diarization}")
        file_path = os.path.join(AUDIO_DIRECTORY, filename)
        file_path = os.path.normpath(file_path)
        file_path = os.path.abspath(file_path)
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - ìš”ì²­ëœ íŒŒì¼ëª…: {filename}")
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - êµ¬ì„±ëœ ê²½ë¡œ: {file_path}")
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(file_path)}")
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename} (ê²½ë¡œ: {file_path})")
        
        if not os.path.isfile(file_path):
            raise HTTPException(status_code=400, detail=f"ìœ íš¨í•œ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {filename} (ê²½ë¡œ: {file_path})")
        
        actual_filename = os.path.basename(filename)
        file_extension = os.path.splitext(actual_filename)[1].lower()
        if file_extension not in SUPPORTED_AUDIO_EXTENSIONS:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_AUDIO_EXTENSIONS)}")
        
        logger.info(f"STT ì²˜ë¦¬ ì‹œì‘ - File ID: {file_id}, íŒŒì¼ê²½ë¡œ: {file_path}")
        logger.info(f"Whisper STT ì²˜ë¦¬ ì¤‘ - ëª¨ë¸: {model_name}")
        
        if model_name in cached_whisper_models:
            logger.info(f"ìºì‹œëœ ëª¨ë¸ ì‚¬ìš©: {model_name}")
            current_model = cached_whisper_models[model_name]
        elif model_name == "base" and whisper_model is not None:
            logger.info("ê¸°ë³¸ base ëª¨ë¸ ì‚¬ìš©")
            current_model = whisper_model
            cached_whisper_models["base"] = whisper_model
        else:
            logger.info(f"ìƒˆ ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
            logger.warning(f"âš ï¸ ëª¨ë¸ '{model_name}' ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            try:
                import time
                start_loading_time = time.time()
                current_model = whisper.load_model(model_name)
                loading_time = time.time() - start_loading_time
                logger.info(f"âœ… ëª¨ë¸ '{model_name}' ë¡œë”© ì™„ë£Œ (ì†Œìš”ì‹œê°„: {loading_time:.2f}ì´ˆ)")
                cached_whisper_models[model_name] = current_model
            except Exception as model_error:
                logger.error(f"âŒ ëª¨ë¸ '{model_name}' ë¡œë”© ì‹¤íŒ¨: {model_error}")
                if model_name != "base" and whisper_model is not None:
                    logger.info("ğŸ”„ ê¸°ë³¸ 'base' ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤...")
                    current_model = whisper_model
                    cached_whisper_models["base"] = whisper_model
                else:
                    raise HTTPException(status_code=500, detail=f"Whisper ëª¨ë¸ '{model_name}' ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(model_error)}")
        
        # STT ì‹¤í–‰
        logger.info(f"Whisper transcribe ì‹œì‘ - íŒŒì¼: {file_path}")
        logger.info(f"Whisper transcribe ì‹œì‘ - ì–¸ì–´: {language}")
        try:
            result = current_model.transcribe(
                file_path, 
                language=language,
                beam_size=1,
                verbose=True,
                no_speech_threshold=0.6,  # ìŒì„± ì—†ëŠ” êµ¬ê°„ ê°ì§€ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                logprob_threshold=-1.0,   # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’ (í’ˆì§ˆ í–¥ìƒ)
                compression_ratio_threshold=2.4,  # ì••ì¶• ë¹„ìœ¨ ì„ê³„ê°’ (íš¨ìœ¨ì„± í–¥ìƒ)
                condition_on_previous_text=True,  # ì´ì „ í…ìŠ¤íŠ¸ ì¡°ê±´í™” (ì •í™•ë„ í–¥ìƒ)
                word_timestamps=False  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)
            )
            logger.info(f"Whisper transcribe ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result.get('text', ''))}")
        except Exception as transcribe_error:
            logger.error(f"Whisper transcribe ì‹¤íŒ¨ - íŒŒì¼: {file_path}")
            logger.error(f"Whisper transcribe ì‹¤íŒ¨ - ì˜¤ë¥˜: {transcribe_error}")
            logger.error(f"Whisper transcribe ì‹¤íŒ¨ - ì˜¤ë¥˜ íƒ€ì…: {type(transcribe_error).__name__}")
            error_msg = str(transcribe_error)
            if "WinError 2" in error_msg or "CreateProcess" in error_msg:
                raise HTTPException(status_code=500, detail="FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. WhisperëŠ” ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤. FFmpegë¥¼ ì„¤ì¹˜í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                raise HTTPException(status_code=500, detail=f"ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì‹¤íŒ¨: {str(transcribe_error)}")
        
        # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì²˜ë¦¬ (ë‹¨ìˆœí™”: ì›ë³¸ + í›„ì²˜ë¦¬)
        segments = []
        original_segments = []  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë³´ì¡´
        
        # ë„ë©”ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (í†µí•© í›„ì²˜ë¦¬ìš©)
        domain_data = None
        if extract_erp and erp_extractor is not None:
            try:
                domain_data = domain_manager.get_domain_data()
            except Exception as e:
                logger.warning(f"ë„ë©”ì¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        for i, segment in enumerate(result.get("segments", [])):
            original_text = segment["text"].strip()
            processed_text = comprehensive_postprocess(original_text, domain_data)
            
            # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ë¡œê·¸ ì¶œë ¥
            logger.info(f"ì„¸ê·¸ë¨¼íŠ¸ {i+1}: ì›ë³¸='{original_text}' â†’ í›„ì²˜ë¦¬='{processed_text}'")
            
            original_segment = {
                "id": i,
                "text": original_text,
                "start": segment["start"],
                "end": segment["end"],
                "speaker": f"Speaker_{i % 2}"
            }
            original_segments.append(original_segment)
            segment_data = {
                "id": i,
                "text": processed_text,
                "start": segment["start"],
                "end": segment["end"],
                "speaker": f"Speaker_{i % 2}"
            }
            segments.append(segment_data)
        
        # ERP ë°ì´í„° ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ê°œì„ )
        erp_data = None
        if extract_erp and segments and erp_extractor is not None:
            try:
                logger.info("ERP ë°ì´í„° ì¶”ì¶œ ì¤‘... (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                erp_dict = erp_extractor.extract_from_segments(segments, filename=filename)
                logger.info(f"ì¶”ì¶œëœ ERP ë”•ì…”ë„ˆë¦¬: {erp_dict}")
                try:
                    erp_data = ERPData(**erp_dict)
                    logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
                except Exception as validation_error:
                    logger.error(f"ERPData ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {validation_error}")
                    logger.error(f"ë¬¸ì œê°€ ëœ ë°ì´í„°: {erp_dict}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                    erp_data = None
            except TimeoutError as e:
                logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ: {e}")
                logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            except Exception as e:
                logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        elif extract_erp and erp_extractor is None:
            logger.info("âš ï¸ ERP Extractorê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ìƒì„± (ì›ë³¸ + í›„ì²˜ë¦¬)
        original_text = result["text"]
        processed_text = comprehensive_postprocess(original_text, domain_data)
        
        # Supabaseì— STT ì„¸ì…˜ ì €ì¥ (í•­ìƒ ì €ì¥)
        session_id = None
        extraction_id = None
        
        if supabase_mgr:
            try:
                logger.info("Supabaseì— STT ê²°ê³¼ ì €ì¥ ì¤‘...")
                session = supabase_mgr.create_stt_session(
                    file_name=filename,
                    file_id=file_id,
                    model_name=model_name,
                    language=language
                )
                session_id = session['id']
                supabase_mgr.update_stt_session(
                    session_id=session_id,
                    transcript=processed_text,
                    original_transcript=original_text,
                    segments=segments,
                    original_segments=original_segments,
                    processing_time=processing_time,
                    status="completed"
                )
                if erp_data:
                    erp_dict = erp_data.dict(by_alias=True)
                    
                    # ì „ì‚¬ ìš”ì•½ í†µí•© (ì„±ëŠ¥ ìµœì í™” - ê°„ë‹¨í•œ ìš”ì•½)
                    try:
                        # ê°„ë‹¨í•œ ìš”ì•½ ìƒì„± (GPT API í˜¸ì¶œ ì—†ì´)
                        simple_summary = _create_simple_summary(processed_text, erp_dict)
                        erp_dict["ìš”ì²­ ì‚¬í•­"] = simple_summary
                        logger.info("ê°„ë‹¨í•œ ìš”ì•½ ê¸°ë°˜ ìš”ì²­ì‚¬í•­ ìƒì„± ì™„ë£Œ")
                    except Exception as e:
                        logger.warning(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
                        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ì„¤ì •
                        erp_dict["ìš”ì²­ ì‚¬í•­"] = "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
                    
                    extraction = supabase_mgr.save_erp_extraction(
                        session_id=session_id,
                        erp_data=erp_dict
                    )
                    extraction_id = extraction['id']
                    logger.info(f"ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
                if save_to_db and extraction_id:
                    try:
                        logger.info("ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ ì¤‘...")
                        erp_id = f"auto{uuid.uuid4().hex[:8]}"
                        erp_response_data = {
                            "status": "success",
                            "erp_id": erp_id,
                            "message": "STT ì²˜ë¦¬ ì¤‘ ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
                        }
                        supabase_mgr.save_erp_register_log(
                            extraction_id=extraction_id,
                            erp_id=erp_id,
                            status="success",
                            response_data=erp_response_data
                        )
                        logger.info(f"ERP ìë™ ë“±ë¡ ì™„ë£Œ - ERP ID: {erp_id}, ì¶”ì¶œ ID: {extraction_id}")
                    except Exception as e:
                        logger.warning(f"ERP ìë™ ë“±ë¡ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                        try:
                            supabase_mgr.save_erp_register_log(
                                extraction_id=extraction_id,
                                erp_id="",
                                status="failed",
                                response_data={"error": str(e)}
                            )
                        except:
                            pass
                logger.info(f"Supabase ì €ì¥ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}")
            except Exception as e:
                logger.warning(f"Supabase ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        response = STTResponse(
            status="success",
            transcript=processed_text,
            segments=segments,
            erp_data=erp_data,
            processing_time=processing_time,
            file_id=file_id,
            original_transcript=original_text,
            original_segments=original_segments
        )
        if session_id:
            response.session_id = session_id
        if extraction_id:
            response.extraction_id = extraction_id
        logger.info(f"STT ì²˜ë¦¬ ì™„ë£Œ - File ID: {file_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
        return response
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"STT ì²˜ë¦¬ ì‹¤íŒ¨ - File ID: {file_id}: {e}")
        raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/models")
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Whisper ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    global cached_whisper_models
    
    available_models = list(cached_whisper_models.keys())
    
    return {
        "available_models": available_models,
        "default_model": "base",
        "model_info": {
            "base": "ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸, ì •í™•ë„ ë‚®ìŒ",
            "small": "ê· í˜•ì¡íŒ ëª¨ë¸, ì†ë„ì™€ ì •í™•ë„ ì¤‘ê°„",
            "medium": "ì •í™•ë„ ë†’ìŒ, ì†ë„ ëŠë¦¼",
            "large": "ê°€ì¥ ì •í™•í•œ ëª¨ë¸, ì†ë„ ë§¤ìš° ëŠë¦¼"
        }
    }

@router.get("/health")
async def stt_health_check():
    """STT ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    global whisper_model, erp_extractor, cached_whisper_models
    
    return {
        "status": "healthy",
        "whisper_model_loaded": whisper_model is not None,
        "erp_extractor_loaded": erp_extractor is not None,
        "cached_models": list(cached_whisper_models.keys()),
        "timestamp": datetime.now().isoformat()
    }