"""
STN ê³ ê°ì„¼í„° STT ì‹œìŠ¤í…œ API ì„œë²„
FastAPI ê¸°ë°˜ REST API ì„œë²„ - ERP ì—°ë™ ë° STT ì²˜ë¦¬
"""

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel, Field
from typing import Dict, List, Optional
import uuid
import json
import os
import tempfile
import whisper
from datetime import datetime, timedelta
import logging
import threading
from postprocessor import postprocess_to_codes, convert_to_legacy_erp_format, extract_requester_name
from domain_manager import domain_manager

# ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë ¨ import (ì„ íƒì )
try:
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.triggers.cron import CronTrigger
    SCHEDULER_AVAILABLE = True
except ImportError:
    BackgroundScheduler = None
    CronTrigger = None
    SCHEDULER_AVAILABLE = False
    print("âš ï¸ APSchedulerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    print("âš ï¸ ì„¤ì¹˜í•˜ë ¤ë©´: pip install APScheduler>=3.10.0")

# ë¡œì»¬ ëª¨ë“ˆ import
from gpt_extractor import ERPExtractor, extract_erp_from_segments
from supabase_client import get_supabase_manager, save_stt_result, save_erp_result
from dotenv import load_dotenv

# í•«ë¦¬ë¡œë“œ ë° ë„ë©”ì¸ ë°ì´í„° ê´€ë ¨ import
from importlib import reload
import gpt_extractor as ge
import domain_loader as dl
from payload_schema import validate_payload, get_validation_stats
import openai
import json

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
import os
config_path = os.path.join(os.path.dirname(__file__), 'config.env')
load_dotenv(config_path)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="STN ê³ ê°ì„¼í„° STT ì‹œìŠ¤í…œ API",
    description="Whisper STT + GPT-3.5-turbo ê¸°ë°˜ ERP í•­ëª© ì¶”ì¶œ ë° ì—°ë™ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 422 ì˜¤ë¥˜ ë””ë²„ê¹…ì„ ìœ„í•œ ì˜ˆì™¸ í•¸ë“¤ëŸ¬
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.error(f"422 ê²€ì¦ ì˜¤ë¥˜ ë°œìƒ - URL: {request.url}")
    logger.error(f"ìš”ì²­ ë©”ì†Œë“œ: {request.method}")
    logger.error(f"ìš”ì²­ í—¤ë”: {dict(request.headers)}")
    
    # ìš”ì²­ ë³¸ë¬¸ ë¡œê¹…
    try:
        body = await request.body()
        logger.error(f"ìš”ì²­ ë³¸ë¬¸: {body.decode('utf-8')}")
    except Exception as e:
        logger.error(f"ìš”ì²­ ë³¸ë¬¸ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ë¡œê¹…
    logger.error(f"ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°: {dict(request.query_params)}")
    
    # ìƒì„¸í•œ ê²€ì¦ ì˜¤ë¥˜ ë¡œê¹…
    logger.error(f"ê²€ì¦ ì˜¤ë¥˜ ìƒì„¸:")
    for error in exc.errors():
        logger.error(f"  - í•„ë“œ: {error.get('loc')}")
        logger.error(f"  - ì˜¤ë¥˜: {error.get('msg')}")
        logger.error(f"  - íƒ€ì…: {error.get('type')}")
        logger.error(f"  - ì…ë ¥ê°’: {error.get('input', 'N/A')}")
    
    return JSONResponse(
        status_code=422,
        content={
            "detail": exc.errors(),
            "message": "ìš”ì²­ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨",
            "debug_info": {
                "url": str(request.url),
                "method": request.method,
                "errors": exc.errors()
            }
        }
    )

# ì „ì—­ ë³€ìˆ˜
whisper_model = None
erp_extractor = None
supabase_manager = None

# ëª¨ë¸ ìºì‹±ìš© ë”•ì…”ë„ˆë¦¬ (ì„±ëŠ¥ ìµœì í™”)
cached_whisper_models = {}

# ë„ë©”ì¸ ë°ì´í„° ìºì‹œ (í•«ë¦¬ë¡œë“œìš©)
# ë„ë©”ì¸ ë°ì´í„°ëŠ” domain_managerì—ì„œ ê´€ë¦¬

def clear_model_cache():
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ëª¨ë¸ ìºì‹œ ì •ë¦¬ í•¨ìˆ˜"""
    global cached_whisper_models
    cached_whisper_models.clear()
    logger.info("ëª¨ë¸ ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

def clear_whisper_file_cache():
    """ì†ìƒëœ Whisper íŒŒì¼ ìºì‹œë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    import os
    import shutil
    from pathlib import Path
    
    try:
        # Windows í™˜ê²½ì—ì„œ Whisper ìºì‹œ ê²½ë¡œ
        cache_paths = [
            Path.home() / ".cache" / "whisper",  # Linux/Mac
            Path(os.getenv('LOCALAPPDATA', '')) / "whisper",  # Windows
            Path(os.getenv('APPDATA', '')) / "whisper",  # Windows ëŒ€ì•ˆ
        ]
        
        cleared_paths = []
        for cache_path in cache_paths:
            if cache_path.exists() and cache_path.is_dir():
                try:
                    shutil.rmtree(cache_path)
                    cleared_paths.append(str(cache_path))
                    logger.info(f"Whisper ìºì‹œ í´ë” ì‚­ì œë¨: {cache_path}")
                except Exception as e:
                    logger.warning(f"ìºì‹œ í´ë” ì‚­ì œ ì‹¤íŒ¨ ({cache_path}): {e}")
        
        if cleared_paths:
            logger.info(f"ì´ {len(cleared_paths)}ê°œì˜ ìºì‹œ í´ë”ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True, cleared_paths
        else:
            logger.info("ì •ë¦¬í•  Whisper ìºì‹œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False, []
            
    except Exception as e:
        logger.error(f"Whisper ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return False, []

# ìƒìˆ˜ ì •ì˜
import os
# ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ src_record ê²½ë¡œ ì„¤ì •
AUDIO_DIRECTORY = os.path.join(os.path.dirname(os.path.abspath(__file__)), "src_record")

# ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¥ì
SUPPORTED_AUDIO_EXTENSIONS = ['.mp3', '.wav', '.m4a', '.flac', '.aac', '.ogg']

# ì¼ìë³„ í´ë” ê´€ë¦¬ í•¨ìˆ˜
def create_daily_directory():
    """
    ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ src_record í•˜ìœ„ì— YYYY-MM-DD í˜•ì‹ì˜ í´ë” ìƒì„±
    """
    try:
        today = datetime.now().strftime('%Y-%m-%d')
        daily_path = os.path.join(AUDIO_DIRECTORY, today)
        
        # ê¸°ë³¸ src_record ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(AUDIO_DIRECTORY):
            os.makedirs(AUDIO_DIRECTORY)
            logger.info(f"ê¸°ë³¸ ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±: {AUDIO_DIRECTORY}")
        
        # ì˜¤ëŠ˜ ë‚ ì§œ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(daily_path):
            os.makedirs(daily_path)
            logger.info(f"ì¼ìë³„ í´ë” ìƒì„±: {daily_path}")
        else:
            logger.info(f"ì¼ìë³„ í´ë” ì´ë¯¸ ì¡´ì¬: {daily_path}")
            
        return daily_path
        
    except Exception as e:
        logger.error(f"ì¼ìë³„ í´ë” ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë ¨ ë³€ìˆ˜
scheduler = None

def create_daily_directory_with_date(target_date=None, auto_create=True):
    """
    íŠ¹ì • ë‚ ì§œì˜ í´ë”ë¥¼ ìƒì„± (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)
    
    Args:
        target_date: ìƒì„±í•  ë‚ ì§œ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
        auto_create: ìë™ ìƒì„± ì—¬ë¶€
    """
    try:
        if target_date is None:
            target_date = datetime.now()
        
        date_str = target_date.strftime('%Y-%m-%d')
        daily_path = os.path.join(AUDIO_DIRECTORY, date_str)
        
        # ê¸°ë³¸ src_record ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(AUDIO_DIRECTORY):
            os.makedirs(AUDIO_DIRECTORY)
            logger.info(f"ê¸°ë³¸ ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±: {AUDIO_DIRECTORY}")
        
        # í•´ë‹¹ ë‚ ì§œ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(daily_path):
            if auto_create:
                os.makedirs(daily_path)
                logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬: ì¼ìë³„ í´ë” ìƒì„± ì™„ë£Œ - {daily_path}")
            else:
                logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬: í´ë” ìƒì„± í•„ìš” - {daily_path} (auto_create=False)")
        else:
            logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬: ì¼ìë³„ í´ë” ì´ë¯¸ ì¡´ì¬ - {daily_path}")
            
        return daily_path
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬: ì¼ìë³„ í´ë” ìƒì„± ì‹¤íŒ¨ - {e}")
        return None

def ensure_today_folder_exists():
    """
    ì˜¤ëŠ˜ ë‚ ì§œ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
    """
    return create_daily_directory_with_date(datetime.now(), auto_create=True)

def scheduled_daily_folder_creation():
    """
    ë§¤ì¼ 0ì‹œì— ì‹¤í–‰ë˜ëŠ” ì¼ë³„ í´ë” ìƒì„± í•¨ìˆ˜
    """
    try:
        today = datetime.now()
        daily_path = create_daily_directory_with_date(today, auto_create=True)
        
        if daily_path:
            logger.info(f"âœ… ìŠ¤ì¼€ì¤„ëŸ¬: {today.strftime('%Y-%m-%d')} í´ë” ìƒì„± ì™„ë£Œ")
        else:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬: {today.strftime('%Y-%m-%d')} í´ë” ìƒì„± ì‹¤íŒ¨")
            
    except Exception as e:
        logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

def get_daily_directory_path(date_str=None):
    """
    íŠ¹ì • ë‚ ì§œì˜ í´ë” ê²½ë¡œë¥¼ ë°˜í™˜ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
    
    Args:
        date_str (str): YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
    
    Returns:
        str: ì¼ìë³„ í´ë” ê²½ë¡œ
    """
    if date_str is None:
        date_str = datetime.now().strftime('%Y-%m-%d')
    
    return os.path.join(AUDIO_DIRECTORY, date_str)

# Pydantic ëª¨ë¸ë“¤
class ERPData(BaseModel):
    """ERP ë“±ë¡ ë°ì´í„° ëª¨ë¸"""
    as_support: str = Field("", alias="AS ë° ì§€ì›", description="ì§€ì› ë°©ì‹ (ë°©ë¬¸ê¸°ìˆ ì§€ì›, ì›ê²©ê¸°ìˆ ì§€ì› ë“±)")
    request_org: str = Field("", alias="ìš”ì²­ê¸°ê´€", description="ê³ ê°ì‚¬ ë˜ëŠ” ê¸°ê´€ëª…")
    work_location: str = Field("", alias="ì‘ì—…êµ­ì†Œ", description="ì§€ì—­ ë˜ëŠ” ìœ„ì¹˜")
    request_date: str = Field("", alias="ìš”ì²­ì¼", description="ê³ ê°ì´ ìš”ì²­í•œ ë‚ ì§œ (YYYY-MM-DD)")
    request_time: str = Field("", alias="ìš”ì²­ì‹œê°„", description="ê³ ê°ì´ ìš”ì²­í•œ ì‹œê°„ (24ì‹œê°„ í˜•ì‹)")
    requester: str = Field("", alias="ìš”ì²­ì", description="ê³ ê° ë‹´ë‹¹ì ì´ë¦„")
    support_count: str = Field("", alias="ì§€ì›ì¸ì›ìˆ˜", description="í•„ìš”í•œ ì§€ì› ì¸ì› ìˆ˜")
    support_staff: str = Field("", alias="ì§€ì›ìš”ì›", description="íˆ¬ì… ì˜ˆì • ê¸°ìˆ ì ì´ë¦„")
    equipment_name: str = Field("", alias="ì¥ë¹„ëª…", description="ì¥ë¹„ ì¢…ë¥˜")
    model_name: str = Field("", alias="ê¸°ì¢…ëª…", description="êµ¬ì²´ì ì¸ ì¥ë¹„ ëª¨ë¸ëª…")
    as_period_status: str = Field("", alias="A/Sê¸°ê°„ë§Œë£Œì—¬ë¶€", description="A/S ê¸°ê°„ ìƒíƒœ (ë¬´ìƒ, ìœ ìƒ)")
    system_name: str = Field("", alias="ì‹œìŠ¤í…œëª…(ê³ ê°ì‚¬ëª…)", description="ê³ ê°ì‚¬ ì‹œìŠ¤í…œëª…")
    request_content: str = Field("", alias="ìš”ì²­ ì‚¬í•­", description="ê³ ê° ìš”ì²­ ë‚´ìš© ìš”ì•½")
    
    class Config:
        allow_population_by_field_name = True
        schema_extra = {
            "example": {
                "AS ë° ì§€ì›": "ì›ê²©ê¸°ìˆ ì§€ì›",
                "ìš”ì²­ê¸°ê´€": "ìˆ˜ìì›ê³µì‚¬ FAë§",
                "ì‘ì—…êµ­ì†Œ": "ëŒ€ì „",
                "ìš”ì²­ì¼": "2025-04-18",
                "ìš”ì²­ì‹œê°„": "15",
                "ìš”ì²­ì": "ì´ì •ìˆœ",
                "ì§€ì›ì¸ì›ìˆ˜": "1ëª…",
                "ì§€ì›ìš”ì›": "ì„ì„ ë¬µ",
                "ì¥ë¹„ëª…": "MSPP",
                "ê¸°ì¢…ëª…": "1646SMC",
                "A/Sê¸°ê°„ë§Œë£Œì—¬ë¶€": "ìœ ìƒ",
                "ì‹œìŠ¤í…œëª…(ê³ ê°ì‚¬ëª…)": "ìˆ˜ìì›ê³µì‚¬ FAë§",
                "ìš”ì²­ ì‚¬í•­": "ìˆ˜ìì› íšŒì„  ë¬¸ì˜ê±´"
            }
        }

class ERPRegisterResponse(BaseModel):
    """ERP ë“±ë¡ ì‘ë‹µ ëª¨ë¸"""
    status: str = Field(..., description="ì²˜ë¦¬ ìƒíƒœ")
    erp_id: str = Field(..., description="ERP ë“±ë¡ ID")
    message: Optional[str] = Field(None, description="ì²˜ë¦¬ ë©”ì‹œì§€")

class STTRequest(BaseModel):
    """STT ì²˜ë¦¬ ìš”ì²­ ëª¨ë¸"""
    model_name: Optional[str] = Field("base", description="Whisper ëª¨ë¸ëª…")
    language: Optional[str] = Field(None, description="ì–¸ì–´ ì½”ë“œ")
    enable_diarization: Optional[bool] = Field(True, description="í™”ì ë¶„ë¦¬ í™œì„±í™”")

class STTResponse(BaseModel):
    """STT ì²˜ë¦¬ ì‘ë‹µ ëª¨ë¸ (í•˜ì´ë¸Œë¦¬ë“œ: ì›ë³¸ + í›„ì²˜ë¦¬)"""
    status: str = Field(..., description="ì²˜ë¦¬ ìƒíƒœ")
    transcript: str = Field(..., description="í›„ì²˜ë¦¬ëœ ì „ì²´ í…ìŠ¤íŠ¸")
    segments: List[Dict] = Field(..., description="í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ë³„ ê²°ê³¼")
    erp_data: Optional[ERPData] = Field(None, description="ì¶”ì¶œëœ ERP ë°ì´í„°")
    processing_time: float = Field(..., description="ì²˜ë¦¬ ì‹œê°„(ì´ˆ)")
    file_id: str = Field(..., description="íŒŒì¼ ì²˜ë¦¬ ID")
    session_id: Optional[int] = Field(None, description="ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ID")
    extraction_id: Optional[int] = Field(None, description="ERP ì¶”ì¶œ ê²°ê³¼ ID")
    
    # í•˜ì´ë¸Œë¦¬ë“œ í•„ë“œ (ì›ë³¸ ë°ì´í„° ë³´ì¡´)
    original_transcript: Optional[str] = Field(None, description="ì›ë³¸ STT í…ìŠ¤íŠ¸")
    original_segments: Optional[List[Dict]] = Field(None, description="ì›ë³¸ STT ì„¸ê·¸ë¨¼íŠ¸")

# ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
def initialize_models():
    """ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ (ì•ˆì „í•œ ë‹¨ê³„ë³„ ì´ˆê¸°í™”)"""
    global whisper_model, erp_extractor, supabase_manager
    
    logger.info("ğŸš€ ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
    
    # 1. Whisper ëª¨ë¸ë“¤ ë¡œë“œ (ê°€ì¥ ì¤‘ìš”)
    try:
        logger.info("1ï¸âƒ£ Whisper ëª¨ë¸ë“¤ ë¡œë”© ì¤‘... (ì¸í„°ë„· ì—°ê²° í•„ìš”)")
        
        # ë¡œë“œí•  ëª¨ë¸ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ)
        models_to_load = ["base", "small", "medium", "large"]
        
        import time
        total_start_time = time.time()
        
        for model_name in models_to_load:
            try:
                logger.info(f"ğŸ“¥ {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
                start_time = time.time()
                model = whisper.load_model(model_name)
                loading_time = time.time() - start_time
                
                # ìºì‹œì— ì €ì¥
                cached_whisper_models[model_name] = model
                
                # base ëª¨ë¸ì€ ì „ì—­ ë³€ìˆ˜ì—ë„ ì €ì¥
                if model_name == "base":
                    whisper_model = model
                
                logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ì†Œìš”ì‹œê°„: {loading_time:.2f}ì´ˆ)")
                
            except Exception as model_error:
                logger.warning(f"âš ï¸ {model_name} ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {model_error}")
                if model_name == "base":
                    # base ëª¨ë¸ì€ í•„ìˆ˜ì´ë¯€ë¡œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬
                    raise
                else:
                    # ë‹¤ë¥¸ ëª¨ë¸ì€ ì„ íƒì ì´ë¯€ë¡œ ê³„ì† ì§„í–‰
                    continue
        
        total_loading_time = time.time() - total_start_time
        loaded_models = list(cached_whisper_models.keys())
        logger.info(f"ğŸ‰ Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (ì´ ì†Œìš”ì‹œê°„: {total_loading_time:.2f}ì´ˆ)")
        logger.info(f"ğŸ“‹ ë¡œë“œëœ ëª¨ë¸: {', '.join(loaded_models)}")
        
    except Exception as e:
        logger.error(f"âŒ Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        logger.error("ğŸ’¡ í•´ê²°ë°©ë²•: ì¸í„°ë„· ì—°ê²° í™•ì¸ ë˜ëŠ” ìºì‹œëœ ëª¨ë¸ ì‚¬ìš©")
        logger.error("ğŸ’¡ ì²´í¬ì„¬ ì˜¤ë¥˜ ì‹œ: ~/.cache/whisper í´ë” ì‚­ì œ í›„ ì¬ì‹œë„")
        raise
    
    # 2. ERP Extractor ì´ˆê¸°í™” (ì„ íƒì )
    try:
        logger.info("2ï¸âƒ£ ERP Extractor ì´ˆê¸°í™” ì¤‘...")
        erp_extractor = ERPExtractor()
        logger.info("âœ… ERP Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ ERP Extractor ì´ˆê¸°í™” ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        logger.warning("ğŸ’¡ í•´ê²°ë°©ë²•: config.envì—ì„œ OPENAI_API_KEY í™•ì¸")
        erp_extractor = None
    
    # 3. Supabase ë§¤ë‹ˆì € ì´ˆê¸°í™” (ì„ íƒì )
    try:
        logger.info("3ï¸âƒ£ Supabase ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        supabase_manager = get_supabase_manager()
        logger.info("âœ… Supabase ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ Supabase ì´ˆê¸°í™” ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        logger.warning("ğŸ’¡ í•´ê²°ë°©ë²•: config.envì—ì„œ Supabase ì„¤ì • í™•ì¸")
        supabase_manager = None
    
    logger.info("ğŸ‰ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!")

# ì˜ì¡´ì„± í•¨ìˆ˜
def get_whisper_model():
    """Whisper ëª¨ë¸ ì˜ì¡´ì„±"""
    if whisper_model is None:
        raise HTTPException(status_code=500, detail="Whisper ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    return whisper_model

def get_erp_extractor():
    """ERP Extractor ì˜ì¡´ì„± (ì„ íƒì )"""
    if erp_extractor is None:
        logger.warning("ERP Extractorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ERP ì¶”ì¶œ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        # ê¸°ë³¸ ê°ì²´ ë°˜í™˜ ë˜ëŠ” None ë°˜í™˜í•˜ì—¬ ì²˜ë¦¬ ë¡œì§ì—ì„œ í™•ì¸í•˜ê²Œ í•¨
        return None
    return erp_extractor

def get_supabase_manager_dep():
    """Supabase ë§¤ë‹ˆì € ì˜ì¡´ì„± (ìë™ ì´ˆê¸°í™” í¬í•¨)"""
    global supabase_manager
    
    # í•­ìƒ ìƒˆë¡œìš´ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜ (ì‹±ê¸€í†¤ ë¬¸ì œ í•´ê²°)
    try:
        logger.info("ğŸ”„ Supabase ë§¤ë‹ˆì € ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        fresh_manager = get_supabase_manager()
        logger.info("âœ… Supabase ë§¤ë‹ˆì € ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        return fresh_manager
    except Exception as e:
        logger.error(f"âŒ Supabase ë§¤ë‹ˆì € ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/")
async def root():
    """API ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "message": "STN ê³ ê°ì„¼í„° STT ì‹œìŠ¤í…œ API ì„œë²„",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    supabase_status = False
    if supabase_manager:
        try:
            supabase_status = supabase_manager.health_check()
        except:
            supabase_status = False
    else:
        # supabase_managerê°€ Noneì¸ ê²½ìš° ì§ì ‘ í…ŒìŠ¤íŠ¸
        try:
            from supabase_client import get_supabase_manager
            test_manager = get_supabase_manager()
            supabase_status = test_manager.health_check()
        except:
            supabase_status = False
    
    scheduler_status = False
    if SCHEDULER_AVAILABLE and scheduler:
        try:
            scheduler_status = scheduler.running
        except:
            scheduler_status = False
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "models": {
            "whisper": whisper_model is not None,
            "erp_extractor": erp_extractor is not None,
            "supabase": supabase_status
        },
        "scheduler": {
            "available": SCHEDULER_AVAILABLE,
            "running": scheduler_status
        }
    }

@app.get("/test")
async def test_endpoint():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "ok",
        "message": "API ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/erp-sample-register", response_model=ERPRegisterResponse)
async def register_erp_sample(
    erp_data: ERPData, 
    extraction_id: Optional[int] = None,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    ERP ì—°ë™ìš© ìƒ˜í”Œ ë“±ë¡ API
    PRD ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ í…ŒìŠ¤íŠ¸ìš© ì¸í„°í˜ì´ìŠ¤
    """
    try:
        # Mock ERP ID ìƒì„±
        erp_id = f"mock{uuid.uuid4().hex[:8]}"
        
        logger.info(f"ERP ìƒ˜í”Œ ë“±ë¡ ìš”ì²­ - ID: {erp_id}")
        logger.info(f"ë“±ë¡ ë°ì´í„°: {erp_data.dict()}")
        
        # ì‹¤ì œ ERP ì‹œìŠ¤í…œ ì—°ë™ ì‹œë®¬ë ˆì´ì…˜ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ì„±ê³µ ì‘ë‹µ)
        response_data = {
            "status": "success",
            "erp_id": erp_id,
            "message": "ERP ì‹œìŠ¤í…œì— ì •ìƒì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
        # Supabaseì— ë“±ë¡ ë¡œê·¸ ì €ì¥
        if extraction_id and supabase_mgr:
            try:
                supabase_mgr.save_erp_register_log(
                    extraction_id=extraction_id,
                    erp_id=erp_id,
                    status="success",
                    response_data=response_data
                )
                logger.info(f"ERP ë“±ë¡ ë¡œê·¸ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
            except Exception as e:
                logger.warning(f"ERP ë“±ë¡ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        response = ERPRegisterResponse(**response_data)
        return response
        
    except Exception as e:
        logger.error(f"ERP ë“±ë¡ ì‹¤íŒ¨: {e}")
        
        # ì‹¤íŒ¨ ë¡œê·¸ë„ ì €ì¥
        if extraction_id and supabase_mgr:
            try:
                supabase_mgr.save_erp_register_log(
                    extraction_id=extraction_id,
                    erp_id="",
                    status="failed",
                    response_data={"error": str(e)}
                )
            except:
                pass
        
        raise HTTPException(status_code=500, detail=f"ERP ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/stt-process", response_model=STTResponse)
async def process_audio_file(
    file: UploadFile = File(..., description="ì—…ë¡œë“œí•  ìŒì„± íŒŒì¼"),
    model_name: str = "base",
    language: Optional[str] = None,
    enable_diarization: bool = True,
    extract_erp: bool = True,
    save_to_db: bool = True,
    whisper_model=Depends(get_whisper_model),
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    ìŒì„± íŒŒì¼ STT ì²˜ë¦¬ ë° ERP í•­ëª© ì¶”ì¶œ API
    """
    start_time = datetime.now()
    file_id = f"stt_{uuid.uuid4().hex[:8]}"
    
    # 'auto' ì–¸ì–´ ì„¤ì •ì„ Noneìœ¼ë¡œ ë³€í™˜
    if language == 'auto':
        language = None
    
    try:
        logger.info(f"STT ì²˜ë¦¬ ì‹œì‘ - File ID: {file_id}, íŒŒì¼ëª…: {file.filename}")
        
        # íŒŒì¼ í˜•ì‹ ê²€ì¦
        allowed_extensions = ['.mp3', '.wav', '.m4a', '.flac']
        file_extension = os.path.splitext(file.filename)[1].lower()
        
        if file_extension not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}"
            )
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            # Whisper STT ì²˜ë¦¬
            logger.info(f"Whisper STT ì²˜ë¦¬ ì¤‘ - ëª¨ë¸: {model_name}")
            
            # ëª¨ë¸ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
            if model_name in cached_whisper_models:
                logger.info(f"ìºì‹œëœ ëª¨ë¸ ì‚¬ìš©: {model_name}")
                current_model = cached_whisper_models[model_name]
            elif model_name == "base" and whisper_model is not None:
                logger.info("ê¸°ë³¸ base ëª¨ë¸ ì‚¬ìš©")
                current_model = whisper_model
                cached_whisper_models["base"] = whisper_model
            else:
                logger.info(f"ìƒˆ ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
                logger.warning(f"âš ï¸ ëª¨ë¸ '{model_name}' ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                try:
                    # ëª¨ë¸ ë¡œë”©ì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¡œê¹… ê°•í™”
                    import time
                    start_loading_time = time.time()
                    current_model = whisper.load_model(model_name)
                    loading_time = time.time() - start_loading_time
                    logger.info(f"âœ… ëª¨ë¸ '{model_name}' ë¡œë”© ì™„ë£Œ (ì†Œìš”ì‹œê°„: {loading_time:.2f}ì´ˆ)")
                    cached_whisper_models[model_name] = current_model
                except Exception as model_error:
                    logger.error(f"âŒ ëª¨ë¸ '{model_name}' ë¡œë”© ì‹¤íŒ¨: {model_error}")
                    
                    # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ë¡œ í´ë°±
                    if model_name != "base" and whisper_model is not None:
                        logger.info("ğŸ”„ ê¸°ë³¸ 'base' ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤...")
                        current_model = whisper_model
                        cached_whisper_models["base"] = whisper_model
                    else:
                        raise HTTPException(
                            status_code=500, 
                            detail=f"Whisper ëª¨ë¸ '{model_name}' ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(model_error)}"
                        )
            
            # STT ì‹¤í–‰ (VAD í•„í„° ì˜µì…˜ ì ìš© - ì†ë„ í–¥ìƒ)
            result = current_model.transcribe(
                temp_file_path, 
                language=language,
                verbose=True,
                no_speech_threshold=0.6,  # ìŒì„± ì—†ëŠ” êµ¬ê°„ ê°ì§€ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                logprob_threshold=-1.0,   # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’ (í’ˆì§ˆ í–¥ìƒ)
                compression_ratio_threshold=2.4,  # ì••ì¶• ë¹„ìœ¨ ì„ê³„ê°’ (íš¨ìœ¨ì„± í–¥ìƒ)
                condition_on_previous_text=True,  # ì´ì „ í…ìŠ¤íŠ¸ ì¡°ê±´í™” (ì •í™•ë„ í–¥ìƒ)
                word_timestamps=False  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)
            )
            
            # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì²˜ë¦¬ (ë‹¨ìˆœí™”: ì›ë³¸ + í›„ì²˜ë¦¬)
            segments = []
            original_segments = []  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë³´ì¡´
            
            # ë„ë©”ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (í†µí•© í›„ì²˜ë¦¬ìš©)
            domain_data = None
            if extract_erp and erp_extractor is not None:
                try:
                    domain_data = domain_manager.get_domain_data()
                except Exception as e:
                    logger.warning(f"ë„ë©”ì¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            for i, segment in enumerate(result.get("segments", [])):
                original_text = segment["text"].strip()
                
                # í†µí•© í›„ì²˜ë¦¬ ì ìš© (ìŒì„± ì •ê·œí™” + ìœ ì‚¬ë„ ë§¤í•‘)
                from postprocessor import comprehensive_postprocess
                processed_text = comprehensive_postprocess(original_text, domain_data)
                
                # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
                original_segment = {
                    "id": i,
                    "text": original_text,
                    "start": segment["start"],
                    "end": segment["end"],
                    "speaker": f"Speaker_{i % 2}"
                }
                original_segments.append(original_segment)
                
                # í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ (ë©”ì¸ ì‚¬ìš©)
                segment_data = {
                    "id": i,
                    "text": processed_text,
                    "start": segment["start"],
                    "end": segment["end"],
                    "speaker": f"Speaker_{i % 2}"
                }
                segments.append(segment_data)
            
            # ERP ë°ì´í„° ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ê°œì„ )
            erp_data = None
            if extract_erp and segments and erp_extractor is not None:
                try:
                    logger.info("ERP ë°ì´í„° ì¶”ì¶œ ì¤‘... (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                    erp_dict = erp_extractor.extract_from_segments(segments, filename=file.filename)
                    logger.info(f"ì¶”ì¶œëœ ERP ë”•ì…”ë„ˆë¦¬: {erp_dict}")
                    
                    # ERPData ëª¨ë¸ ìƒì„± ì‹œ ë” ìì„¸í•œ ì—ëŸ¬ ë¡œê¹…
                    try:
                        erp_data = ERPData(**erp_dict)
                        logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
                    except Exception as validation_error:
                        logger.error(f"ERPData ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {validation_error}")
                        logger.error(f"ë¬¸ì œê°€ ëœ ë°ì´í„°: {erp_dict}")
                        logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                        erp_data = None
                        
                except TimeoutError as e:
                    logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ: {e}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                except Exception as e:
                    logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            elif extract_erp and erp_extractor is None:
                logger.info("âš ï¸ ERP Extractorê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ìƒì„± (ì›ë³¸ + í›„ì²˜ë¦¬)
            original_text = result["text"]
            processed_text = comprehensive_postprocess(original_text, domain_data)
            
            # Supabaseì— STT ì„¸ì…˜ ì €ì¥ (í•­ìƒ ì €ì¥)
            session_id = None
            extraction_id = None
            
            if supabase_mgr:
                try:
                    logger.info("Supabaseì— STT ê²°ê³¼ ì €ì¥ ì¤‘...")
                    
                    # STT ì„¸ì…˜ ìƒì„± ë° ì—…ë°ì´íŠ¸
                    session = supabase_mgr.create_stt_session(
                        file_name=file.filename,
                        file_id=file_id,
                        model_name=model_name,
                        language=language
                    )
                    session_id = session['id']
                    
                    # STT ê²°ê³¼ ì—…ë°ì´íŠ¸ (í•˜ì´ë¸Œë¦¬ë“œ: ì›ë³¸ + í›„ì²˜ë¦¬)
                    supabase_mgr.update_stt_session(
                        session_id=session_id,
                        transcript=processed_text,  # í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ë©”ì¸ìœ¼ë¡œ ì €ì¥
                        original_transcript=original_text,  # ì›ë³¸ í…ìŠ¤íŠ¸ ë³„ë„ ì €ì¥
                        segments=segments,  # í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸
                        original_segments=original_segments,  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë³„ë„ ì €ì¥
                        processing_time=processing_time,
                        status="completed"
                    )
                    
                    # ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ (save_to_db ì˜µì…˜ì— ë”°ë¼)
                    if erp_data and save_to_db:
                        erp_dict = erp_data.dict(by_alias=True)
                        extraction = supabase_mgr.save_erp_extraction(
                            session_id=session_id,
                            erp_data=erp_dict
                        )
                        extraction_id = extraction['id']
                        logger.info(f"ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
                    elif erp_data and not save_to_db:
                        logger.info("ERP ì¶”ì¶œ ê²°ê³¼ëŠ” ìƒì„±ë˜ì—ˆì§€ë§Œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì§€ ì•ŠìŒ (save_to_db=false)")
                        
                    # ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ (DB ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°)
                    if save_to_db and extraction_id:
                        try:
                            logger.info("ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ ì¤‘...")
                            
                            # Mock ERP ID ìƒì„±
                            erp_id = f"auto{uuid.uuid4().hex[:8]}"
                            
                            # ERP ë“±ë¡ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ERP ì‹œìŠ¤í…œ ì—°ë™ ì‹œ ì´ ë¶€ë¶„ì„ ìˆ˜ì •)
                            erp_response_data = {
                                "status": "success",
                                "erp_id": erp_id,
                                "message": "STT ì²˜ë¦¬ ì¤‘ ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
                            }
                            
                            # ERP ë“±ë¡ ë¡œê·¸ ì €ì¥
                            supabase_mgr.save_erp_register_log(
                                extraction_id=extraction_id,
                                erp_id=erp_id,
                                status="success",
                                response_data=erp_response_data
                            )
                            
                            logger.info(f"ERP ìë™ ë“±ë¡ ì™„ë£Œ - ERP ID: {erp_id}, ì¶”ì¶œ ID: {extraction_id}")
                            
                        except Exception as e:
                            logger.warning(f"ERP ìë™ ë“±ë¡ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                            # ì‹¤íŒ¨ ë¡œê·¸ë„ ì €ì¥
                            try:
                                supabase_mgr.save_erp_register_log(
                                    extraction_id=extraction_id,
                                    erp_id="",
                                    status="failed",
                                    response_data={"error": str(e)}
                                )
                            except:
                                pass
                    
                    logger.info(f"Supabase ì €ì¥ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}")
                    
                except Exception as e:
                    logger.warning(f"Supabase ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            
            # ì‘ë‹µ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ: ì›ë³¸ + í›„ì²˜ë¦¬)
            response = STTResponse(
                status="success",
                transcript=processed_text,  # í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ë©”ì¸ìœ¼ë¡œ ë°˜í™˜
                segments=segments,  # í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸
                erp_data=erp_data,
                processing_time=processing_time,
                file_id=file_id,
                original_transcript=original_text,  # ì›ë³¸ í…ìŠ¤íŠ¸
                original_segments=original_segments  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸
            )
            
            # ì‘ë‹µì— DB ì €ì¥ ì •ë³´ ì¶”ê°€ (ë™ì  í•„ë“œ)
            if session_id:
                response.session_id = session_id
            if extraction_id:
                response.extraction_id = extraction_id
            
            logger.info(f"STT ì²˜ë¦¬ ì™„ë£Œ - File ID: {file_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            return response
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"STT ì²˜ë¦¬ ì‹¤íŒ¨ - File ID: {file_id}: {e}")
        raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/stt-process-file", response_model=STTResponse)
async def process_audio_file_from_directory(
    filename: str,
    model_name: str = "base",
    language: Optional[str] = None,
    enable_diarization: bool = True,
    extract_erp: bool = True,
    save_to_db: bool = True,
    whisper_model=Depends(get_whisper_model),
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    src_record ë””ë ‰í† ë¦¬ì˜ ìŒì„± íŒŒì¼ STT ì²˜ë¦¬ ë° ERP í•­ëª© ì¶”ì¶œ API
    """
    start_time = datetime.now()
    file_id = f"stt_{uuid.uuid4().hex[:8]}"
    
    # 'auto' ì–¸ì–´ ì„¤ì •ì„ Noneìœ¼ë¡œ ë³€í™˜
    if language == 'auto':
        language = None
    
    try:
        # íŒŒì¼ ê²½ë¡œ ê²€ì¦ (ì¼ìë³„ í´ë” êµ¬ì¡° ì§€ì›)
        # filenameì´ "ë‚ ì§œí´ë”/íŒŒì¼ëª…" í˜•ì‹ì´ê±°ë‚˜ ë‹¨ìˆœíˆ "íŒŒì¼ëª…"ì¼ ìˆ˜ ìˆìŒ
        file_path = os.path.join(AUDIO_DIRECTORY, filename)
        
        # Windows ê²½ë¡œ ì •ê·œí™”
        file_path = os.path.normpath(file_path)
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (Whisperê°€ ìƒëŒ€ ê²½ë¡œì—ì„œ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŒ)
        file_path = os.path.abspath(file_path)
        
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - ìš”ì²­ëœ íŒŒì¼ëª…: {filename}")
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - êµ¬ì„±ëœ ê²½ë¡œ: {file_path}")
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(file_path)}")
        
        if not os.path.exists(file_path):
            raise HTTPException(
                status_code=404, 
                detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename} (ê²½ë¡œ: {file_path})"
            )
        
        if not os.path.isfile(file_path):
            raise HTTPException(
                status_code=400, 
                detail=f"ìœ íš¨í•œ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {filename} (ê²½ë¡œ: {file_path})"
            )
        
        # íŒŒì¼ í˜•ì‹ ê²€ì¦ (ì‹¤ì œ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì¶”ì¶œ)
        actual_filename = os.path.basename(filename)  # ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
        file_extension = os.path.splitext(actual_filename)[1].lower()
        
        if file_extension not in SUPPORTED_AUDIO_EXTENSIONS:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_AUDIO_EXTENSIONS)}"
            )
        
        logger.info(f"STT ì²˜ë¦¬ ì‹œì‘ - File ID: {file_id}, íŒŒì¼ê²½ë¡œ: {file_path}")
        
        # Whisper STT ì²˜ë¦¬
        logger.info(f"Whisper STT ì²˜ë¦¬ ì¤‘ - ëª¨ë¸: {model_name}")
        
        # ëª¨ë¸ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
        if model_name in cached_whisper_models:
            logger.info(f"ìºì‹œëœ ëª¨ë¸ ì‚¬ìš©: {model_name}")
            current_model = cached_whisper_models[model_name]
        elif model_name == "base" and whisper_model is not None:
            logger.info("ê¸°ë³¸ base ëª¨ë¸ ì‚¬ìš©")
            current_model = whisper_model
            cached_whisper_models["base"] = whisper_model
        else:
            logger.info(f"ìƒˆ ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
            logger.warning(f"âš ï¸ ëª¨ë¸ '{model_name}' ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            try:
                # ëª¨ë¸ ë¡œë”©ì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¡œê¹… ê°•í™”
                import time
                start_loading_time = time.time()
                current_model = whisper.load_model(model_name)
                loading_time = time.time() - start_loading_time
                logger.info(f"âœ… ëª¨ë¸ '{model_name}' ë¡œë”© ì™„ë£Œ (ì†Œìš”ì‹œê°„: {loading_time:.2f}ì´ˆ)")
                cached_whisper_models[model_name] = current_model
            except Exception as model_error:
                logger.error(f"âŒ ëª¨ë¸ '{model_name}' ë¡œë”© ì‹¤íŒ¨: {model_error}")
                
                # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ë¡œ í´ë°±
                if model_name != "base" and whisper_model is not None:
                    logger.info("ğŸ”„ ê¸°ë³¸ 'base' ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤...")
                    current_model = whisper_model
                    cached_whisper_models["base"] = whisper_model
                else:
                    raise HTTPException(
                        status_code=500, 
                        detail=f"Whisper ëª¨ë¸ '{model_name}' ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(model_error)}"
                    )
        
        # STT ì‹¤í–‰
        logger.info(f"Whisper transcribe ì‹œì‘ - íŒŒì¼: {file_path}")
        logger.info(f"Whisper transcribe ì‹œì‘ - ì–¸ì–´: {language}")
        
        try:
            result = current_model.transcribe(
                file_path, 
                language=language,
                verbose=True,
                no_speech_threshold=0.6,  # ìŒì„± ì—†ëŠ” êµ¬ê°„ ê°ì§€ ì„ê³„ê°’ (ì†ë„ í–¥ìƒ)
                logprob_threshold=-1.0,   # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’ (í’ˆì§ˆ í–¥ìƒ)
                compression_ratio_threshold=2.4,  # ì••ì¶• ë¹„ìœ¨ ì„ê³„ê°’ (íš¨ìœ¨ì„± í–¥ìƒ)
                condition_on_previous_text=True,  # ì´ì „ í…ìŠ¤íŠ¸ ì¡°ê±´í™” (ì •í™•ë„ í–¥ìƒ)
                word_timestamps=False  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)
            )
            logger.info(f"Whisper transcribe ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result.get('text', ''))}")
        except Exception as transcribe_error:
            logger.error(f"Whisper transcribe ì‹¤íŒ¨ - íŒŒì¼: {file_path}")
            logger.error(f"Whisper transcribe ì‹¤íŒ¨ - ì˜¤ë¥˜: {transcribe_error}")
            logger.error(f"Whisper transcribe ì‹¤íŒ¨ - ì˜¤ë¥˜ íƒ€ì…: {type(transcribe_error).__name__}")
            
            # FFmpeg ê´€ë ¨ ì˜¤ë¥˜ ê°ì§€
            error_msg = str(transcribe_error)
            if "WinError 2" in error_msg or "CreateProcess" in error_msg:
                raise HTTPException(
                    status_code=500,
                    detail="FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. WhisperëŠ” ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤. FFmpegë¥¼ ì„¤ì¹˜í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                )
            else:
                raise HTTPException(
                    status_code=500,
                    detail=f"ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì‹¤íŒ¨: {str(transcribe_error)}"
                )
        
        # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì²˜ë¦¬ (ë‹¨ìˆœí™”: ì›ë³¸ + í›„ì²˜ë¦¬)
        segments = []
        original_segments = []  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë³´ì¡´
        
        # ë„ë©”ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (í†µí•© í›„ì²˜ë¦¬ìš©)
        domain_data = None
        if extract_erp and erp_extractor is not None:
            try:
                domain_data = domain_manager.get_domain_data()
            except Exception as e:
                logger.warning(f"ë„ë©”ì¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        for i, segment in enumerate(result.get("segments", [])):
            original_text = segment["text"].strip()
            
            # í†µí•© í›„ì²˜ë¦¬ ì ìš© (ìŒì„± ì •ê·œí™” + ìœ ì‚¬ë„ ë§¤í•‘)
            from postprocessor import comprehensive_postprocess
            processed_text = comprehensive_postprocess(original_text, domain_data)
            
            # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
            original_segment = {
                "id": i,
                "text": original_text,
                "start": segment["start"],
                "end": segment["end"],
                "speaker": f"Speaker_{i % 2}"
            }
            original_segments.append(original_segment)
            
            # í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ (ë©”ì¸ ì‚¬ìš©)
            segment_data = {
                "id": i,
                "text": processed_text,
                "start": segment["start"],
                "end": segment["end"],
                "speaker": f"Speaker_{i % 2}"
            }
            segments.append(segment_data)
        
        # ERP ë°ì´í„° ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ê°œì„ )
        erp_data = None
        if extract_erp and segments and erp_extractor is not None:
            try:
                logger.info("ERP ë°ì´í„° ì¶”ì¶œ ì¤‘... (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                erp_dict = erp_extractor.extract_from_segments(segments, filename=filename)
                logger.info(f"ì¶”ì¶œëœ ERP ë”•ì…”ë„ˆë¦¬: {erp_dict}")
                
                # ERPData ëª¨ë¸ ìƒì„± ì‹œ ë” ìì„¸í•œ ì—ëŸ¬ ë¡œê¹…
                try:
                    erp_data = ERPData(**erp_dict)
                    logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
                except Exception as validation_error:
                    logger.error(f"ERPData ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {validation_error}")
                    logger.error(f"ë¬¸ì œê°€ ëœ ë°ì´í„°: {erp_dict}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                    erp_data = None
                    
            except TimeoutError as e:
                logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ: {e}")
                logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            except Exception as e:
                logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        elif extract_erp and erp_extractor is None:
            logger.info("âš ï¸ ERP Extractorê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ìƒì„± (ì›ë³¸ + í›„ì²˜ë¦¬)
        original_text = result["text"]
        processed_text = comprehensive_postprocess(original_text, domain_data)
        
        # Supabaseì— STT ì„¸ì…˜ ì €ì¥ (í•­ìƒ ì €ì¥)
        session_id = None
        extraction_id = None
        
        if supabase_mgr:
            try:
                logger.info("Supabaseì— STT ê²°ê³¼ ì €ì¥ ì¤‘...")
                
                # STT ì„¸ì…˜ ìƒì„± ë° ì—…ë°ì´íŠ¸
                session = supabase_mgr.create_stt_session(
                    file_name=filename,
                    file_id=file_id,
                    model_name=model_name,
                    language=language
                )
                session_id = session['id']
                
                # STT ê²°ê³¼ ì—…ë°ì´íŠ¸ (í•˜ì´ë¸Œë¦¬ë“œ: ì›ë³¸ + í›„ì²˜ë¦¬)
                supabase_mgr.update_stt_session(
                    session_id=session_id,
                    transcript=processed_text,  # í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ë©”ì¸ìœ¼ë¡œ ì €ì¥
                    original_transcript=original_text,  # ì›ë³¸ í…ìŠ¤íŠ¸ ë³„ë„ ì €ì¥
                    segments=segments,  # í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸
                    original_segments=original_segments,  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë³„ë„ ì €ì¥
                    processing_time=processing_time,
                    status="completed"
                )
                
                # ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ (save_to_db ì˜µì…˜ì— ë”°ë¼)
                if erp_data and save_to_db:
                    erp_dict = erp_data.dict(by_alias=True)
                    extraction = supabase_mgr.save_erp_extraction(
                        session_id=session_id,
                        erp_data=erp_dict
                    )
                    extraction_id = extraction['id']
                    logger.info(f"ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
                elif erp_data and not save_to_db:
                    logger.info("ERP ì¶”ì¶œ ê²°ê³¼ëŠ” ìƒì„±ë˜ì—ˆì§€ë§Œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì§€ ì•ŠìŒ (save_to_db=false)")
                
                # ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ (DB ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°)
                if save_to_db and extraction_id:
                    try:
                        logger.info("ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ ì¤‘...")
                        
                        # Mock ERP ID ìƒì„±
                        erp_id = f"auto{uuid.uuid4().hex[:8]}"
                        
                        # ERP ë“±ë¡ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ERP ì‹œìŠ¤í…œ ì—°ë™ ì‹œ ì´ ë¶€ë¶„ì„ ìˆ˜ì •)
                        erp_response_data = {
                            "status": "success",
                            "erp_id": erp_id,
                            "message": "STT ì²˜ë¦¬ ì¤‘ ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
                        }
                        
                        # ERP ë“±ë¡ ë¡œê·¸ ì €ì¥
                        supabase_mgr.save_erp_register_log(
                            extraction_id=extraction_id,
                            erp_id=erp_id,
                            status="success",
                            response_data=erp_response_data
                        )
                        
                        logger.info(f"ERP ìë™ ë“±ë¡ ì™„ë£Œ - ERP ID: {erp_id}, ì¶”ì¶œ ID: {extraction_id}")
                        
                    except Exception as e:
                        logger.warning(f"ERP ìë™ ë“±ë¡ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                        # ì‹¤íŒ¨ ë¡œê·¸ë„ ì €ì¥
                        try:
                            supabase_mgr.save_erp_register_log(
                                extraction_id=extraction_id,
                                erp_id="",
                                status="failed",
                                response_data={"error": str(e)}
                            )
                        except:
                            pass
                
                logger.info(f"Supabase ì €ì¥ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}")
                
            except Exception as e:
                logger.warning(f"Supabase ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        # ì‘ë‹µ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ: ì›ë³¸ + í›„ì²˜ë¦¬)
        response = STTResponse(
            status="success",
            transcript=processed_text,  # í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ë©”ì¸ìœ¼ë¡œ ë°˜í™˜
            segments=segments,  # í›„ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸
            erp_data=erp_data,
            processing_time=processing_time,
            file_id=file_id,
            original_transcript=original_text,  # ì›ë³¸ í…ìŠ¤íŠ¸
            original_segments=original_segments  # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸
        )
        
        # ì‘ë‹µì— DB ì €ì¥ ì •ë³´ ì¶”ê°€ (ë™ì  í•„ë“œ)
        if session_id:
            response.session_id = session_id
        if extraction_id:
            response.extraction_id = extraction_id
        
        logger.info(f"STT ì²˜ë¦¬ ì™„ë£Œ - File ID: {file_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"STT ì²˜ë¦¬ ì‹¤íŒ¨ - File ID: {file_id}: {e}")
        raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/extract-erp")
async def extract_erp_from_text(
    conversation_text: str,
    erp_extractor=Depends(get_erp_extractor)
):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ERP í•­ëª©ì„ ì¶”ì¶œí•˜ëŠ” API
    """
    try:
        logger.info("í…ìŠ¤íŠ¸ì—ì„œ ERP ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        erp_dict = erp_extractor.extract_erp_data(conversation_text)
        erp_data = ERPData(**erp_dict)
        
        return {
            "status": "success",
            "erp_data": erp_data,
            "message": "ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ"
        }
        
    except Exception as e:
        logger.error(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ERP ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# STN ë„ë©”ì¸ ë°ì´í„° ì—°ë™ APIë“¤

@app.get("/api/domain-stats")
async def get_domain_stats():
    """ë„ë©”ì¸ ë°ì´í„° í†µê³„ ì¡°íšŒ"""
    try:
        return domain_manager.get_domain_stats()
    except Exception as e:
        logger.error(f"ë„ë©”ì¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"available": False, "error": str(e)}

@app.post("/api/reload-domain")
async def reload_domain():
    """
    ë„ë©”ì¸ ë°ì´í„° í•«ë¦¬ë¡œë“œ API
    - ì„œë²„ ì¬ì‹œì‘ ì—†ì´ Excel íŒŒì¼ ë³€ê²½ì‚¬í•­ ë°˜ì˜
    - ìºì‹œ ì´ˆê¸°í™” ë° ìƒˆ ë°ì´í„° ë¡œë“œ
    """
    try:
        logger.info("ğŸ”„ ë„ë©”ì¸ ë°ì´í„° í•«ë¦¬ë¡œë“œ ì‹œì‘...")
        
        # ë„ë©”ì¸ ë§¤ë‹ˆì €ì—ì„œ ìƒˆ ë°ì´í„° ë¡œë“œ
        domain_manager._load_domain_data()
        
        # í†µê³„ ì •ë³´
        stats = domain_manager.get_domain_stats()
        
        logger.info("âœ… ë„ë©”ì¸ ë°ì´í„° í•«ë¦¬ë¡œë“œ ì™„ë£Œ")
        return {
            "status": "success",
            "message": "ë„ë©”ì¸ ë°ì´í„° ë¦¬ë¡œë“œ ì™„ë£Œ",
            "stats": stats,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ ë„ë©”ì¸ ë°ì´í„° ë¦¬ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë„ë©”ì¸ ë°ì´í„° ë¦¬ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

class ERPExtractionRequest(BaseModel):
    """ERP ì¶”ì¶œ ìš”ì²­ ëª¨ë¸"""
    transcript_text: str
    use_legacy_format: bool = True
    temperature: float = 0.1
    max_tokens: int = 500

@app.post("/api/extract-erp-enhanced")
async def extract_erp_enhanced(request: ERPExtractionRequest):
    """
    ê°œì„ ëœ ERP ì¶”ì¶œ API
    - STN ë„ë©”ì¸ ë°ì´í„° í™œìš©
    - ì‹¤ì‹œê°„ ê²€ì¦ ë° í›„ì²˜ë¦¬
    - ë ˆê±°ì‹œ í˜¸í™˜ì„± ì§€ì›
    """
    try:
        logger.info("ğŸ” ê°œì„ ëœ ERP ì¶”ì¶œ ì‹œì‘...")
        
        # ë„ë©”ì¸ ë°ì´í„° í™•ì¸
        domain_data = domain_manager.get_domain_data()
        
        # 1. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = domain_manager.build_enhanced_system_prompt()
        user_prompt = _build_enhanced_user_prompt(request.transcript_text, domain_data)
        
        # 2. OpenAI API í˜¸ì¶œ
        api_key = os.getenv('OPENAI_API_KEY')
        client = openai.OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        
        raw_content = response.choices[0].message.content.strip()
        logger.info(f"GPT ì›ì‹œ ì‘ë‹µ: {raw_content}")
        
        # 3. JSON íŒŒì‹±
        try:
            raw_json = json.loads(raw_content)
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            raw_json = {"ì¥ë¹„ëª…": None, "ì¥ì• ìœ í˜•": None, "ìš”ì²­ìœ í˜•": None, "ìœ„ì¹˜": None}
        
        # 4. í›„ì²˜ë¦¬ (ë¼ë²¨â†’ì½”ë“œ ë³€í™˜, ëª¨ë¸ëª… ë§¤í•‘ ë“±)
        processed_payload = postprocess_to_codes(raw_json, domain_data)
        
        # 5. ìŠ¤í‚¤ë§ˆ ê²€ì¦
        try:
            validate_payload(processed_payload, domain_data)
            validation_stats = get_validation_stats(processed_payload, domain_data)
        except Exception as e:
            logger.warning(f"ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
            # ê²€ì¦ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            validation_stats = {"valid_equipment": False, "valid_error": False, "valid_request": False, "warnings": [str(e)]}
        
        # 6. ì‘ë‹µ êµ¬ì„±
        result = {
            "status": "success",
            "stn_format": processed_payload,
            "validation": validation_stats,
            "raw_gpt_response": raw_json,
            "processing_info": {
                "model": "gpt-3.5-turbo",
                "temperature": request.temperature,
                "domain_data_used": True,
                "timestamp": datetime.now().isoformat()
            }
        }
        
        # 7. ë ˆê±°ì‹œ í˜•ì‹ ë³€í™˜ (ì˜µì…˜)
        if request.use_legacy_format:
            # íŒŒì¼ëª… ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´ ì „ë‹¬ (ì„¸ì…˜ ì¬ì²˜ë¦¬ ì‹œì—ëŠ” íŒŒì¼ëª… ì •ë³´ ì—†ìŒ)
            legacy_data = convert_to_legacy_erp_format(processed_payload, request.transcript_text, "")
            result["legacy_format"] = legacy_data
        
        logger.info("âœ… ê°œì„ ëœ ERP ì¶”ì¶œ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ERP ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ERP ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ë°ì´í„° ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/api/sessions")
async def get_stt_sessions(
    limit: int = 50, 
    offset: int = 0
):
    """STT ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
    try:
        # í™˜ê²½ë³€ìˆ˜ ê°•ì œ ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
        from dotenv import load_dotenv
        import os
        config_path = os.path.join(os.getcwd(), 'config.env')
        load_dotenv(config_path)
        
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        supabase_url = os.getenv('SUPABASE_URL')
        supabase_key = os.getenv('SUPABASE_ANON_KEY')
        
        if not supabase_url or not supabase_key:
            return {
                "status": "error",
                "message": f"í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨ - URL: {bool(supabase_url)}, KEY: {bool(supabase_key)}",
                "sessions": [],
                "total": 0
            }
        
        # ì§ì ‘ Supabase ë§¤ë‹ˆì € ìƒì„±
        from supabase_client import get_supabase_manager
        supabase_mgr = get_supabase_manager()
        
        sessions = supabase_mgr.get_stt_sessions(limit=limit, offset=offset)
        return {
            "status": "success",
            "sessions": sessions,
            "total": len(sessions)
        }
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "message": f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {str(e)}",
            "sessions": [],
            "total": 0
        }

@app.get("/api/sessions/{session_id}")
async def get_stt_session(
    session_id: int,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """íŠ¹ì • STT ì„¸ì…˜ ìƒì„¸ ì¡°íšŒ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        session = supabase_mgr.get_stt_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ERP ì¶”ì¶œ ê²°ê³¼ë„ í•¨ê»˜ ì¡°íšŒ
        erp_extraction = supabase_mgr.get_erp_extraction(session_id)
        
        return {
            "status": "success",
            "session": session,
            "erp_extraction": erp_extraction
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/sessions/{session_id}/extract-erp")
async def extract_erp_for_session(
    session_id: int,
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """ê¸°ì¡´ STT ì„¸ì…˜ì— ëŒ€í•œ ERP ì¬ì¶”ì¶œ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        logger.info(f"ì„¸ì…˜ {session_id}ì— ëŒ€í•œ ERP ì¬ì¶”ì¶œ ì‹œì‘")
        
        # ì„¸ì…˜ ì •ë³´ ì¡°íšŒ
        session = supabase_mgr.get_stt_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # transcript ë˜ëŠ” segments í™•ì¸
        transcript = session.get('transcript')
        segments = session.get('segments')
        filename = session.get('file_name', '')  # íŒŒì¼ëª… ì •ë³´ ì¶”ê°€
        
        if not transcript and not segments:
            raise HTTPException(status_code=400, detail="ì„¸ì…˜ì— í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ERP ë°ì´í„° ì¶”ì¶œ
        erp_data = None
        try:
            if segments:
                # ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆìœ¼ë©´ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì¶”ì¶œ
                logger.info("ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ERP ë°ì´í„° ì¶”ì¶œ ì¤‘...")
                
                # segmentsê°€ ë¬¸ìì—´ì¸ ê²½ìš° JSONìœ¼ë¡œ íŒŒì‹±
                if isinstance(segments, str):
                    try:
                        segments = json.loads(segments)
                        logger.info("ì„¸ê·¸ë¨¼íŠ¸ JSON íŒŒì‹± ì™„ë£Œ")
                    except json.JSONDecodeError as e:
                        logger.warning(f"ì„¸ê·¸ë¨¼íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
                        segments = None
                
                if segments and isinstance(segments, list):
                    erp_dict = erp_extractor.extract_from_segments(segments, filename=filename)
                else:
                    logger.info("ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                    erp_dict = erp_extractor.extract_erp_data(transcript, filename=filename)
            else:
                # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
                logger.info("ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ERP ë°ì´í„° ì¶”ì¶œ ì¤‘...")
                erp_dict = erp_extractor.extract_erp_data(transcript, filename=filename)
            
            erp_data = ERPData(**erp_dict)
            logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
            
        except Exception as e:
            logger.error(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        
        # ê¸°ì¡´ ERP ì¶”ì¶œ ê²°ê³¼ í™•ì¸
        existing_extraction = supabase_mgr.get_erp_extraction(session_id)
        
        extraction_id = None
        if existing_extraction:
            # ê¸°ì¡´ ì¶”ì¶œ ê²°ê³¼ ì—…ë°ì´íŠ¸
            logger.info(f"ê¸°ì¡´ ERP ì¶”ì¶œ ê²°ê³¼ ì—…ë°ì´íŠ¸ - ì¶”ì¶œ ID: {existing_extraction['id']}")
            updated_extraction = supabase_mgr.update_erp_extraction(
                extraction_id=existing_extraction['id'],
                erp_data=erp_data.dict(by_alias=True)
            )
            extraction_id = updated_extraction['id']
        else:
            # ìƒˆë¡œìš´ ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥
            logger.info("ìƒˆë¡œìš´ ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥")
            new_extraction = supabase_mgr.save_erp_extraction(
                session_id=session_id,
                erp_data=erp_data.dict(by_alias=True)
            )
            extraction_id = new_extraction['id']
        
        logger.info(f"ERP ì¬ì¶”ì¶œ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}, ì¶”ì¶œ ID: {extraction_id}")
        
        return {
            "status": "success",
            "message": "ERP ì¬ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "session_id": session_id,
            "extraction_id": extraction_id,
            "erp_data": erp_data
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ERP ì¬ì¶”ì¶œ ì‹¤íŒ¨ - ì„¸ì…˜ ID: {session_id}: {e}")
        raise HTTPException(status_code=500, detail=f"ERP ì¬ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/extractions")
async def get_erp_extractions(
    limit: int = 50, 
    offset: int = 0,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """ERP ì¶”ì¶œ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ"""
    # Supabaseê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ëª©ë¡ ë°˜í™˜
    if not supabase_mgr:
        logger.warning("âš ï¸ Supabase ì—°ê²° ì—†ìŒ. ë¹ˆ ì¶”ì¶œ ê²°ê³¼ ëª©ë¡ ë°˜í™˜")
        return {
            "status": "success",
            "message": "Supabase ì—°ê²° ì—†ìŒ - ë¹ˆ ëª©ë¡",
            "extractions": [],
            "total": 0,
            "note": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ í•„ìš”í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤."
        }
    
    try:
        extractions = supabase_mgr.get_erp_extractions(limit=limit, offset=offset)
        return {
            "status": "success",
            "extractions": extractions,
            "total": len(extractions)
        }
    except Exception as e:
        logger.error(f"ì¶”ì¶œ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì¶”ì¶œ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/statistics")
async def get_system_statistics(
    date_filter: Optional[str] = None,
    month_filter: Optional[str] = None,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ
    
    Args:
        date_filter: YYYY-MM-DD í˜•ì‹ì˜ íŠ¹ì • ë‚ ì§œ í•„í„°
        month_filter: YYYY-MM í˜•ì‹ì˜ ì›”ë³„ í•„í„°
    """
    # Supabaseê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í†µê³„ ë°˜í™˜
    if not supabase_mgr:
        logger.warning("âš ï¸ Supabase ì—°ê²° ì—†ìŒ. ê¸°ë³¸ í†µê³„ ë°˜í™˜")
        return {
            "status": "success",
            "message": "Supabase ì—°ê²° ì—†ìŒ - ê¸°ë³¸ í†µê³„",
            "statistics": {
                "total_sessions": 0,
                "total_extractions": 0,
                "success_rate": 0.0,
                "today_processed": 0,
                "avg_processing_time": 0.0,
                "note": "Supabase ì—°ê²°ì´ í•„ìš”í•œ ìƒì„¸ í†µê³„ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            },
            "timestamp": datetime.now().isoformat()
        }
    
    try:
        # ë‚ ì§œ í•„í„°ë§ íŒŒë¼ë¯¸í„° ê²°ì •
        filter_params = {}
        if date_filter:
            filter_params['date_filter'] = date_filter
        elif month_filter:
            filter_params['month_filter'] = month_filter
        
        stats = supabase_mgr.get_statistics(**filter_params)
        return {
            "status": "success",
            "statistics": stats,
            "applied_filter": {
                "date_filter": date_filter,
                "month_filter": month_filter
            }
        }
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/audio-files")
async def get_audio_files():
    """
    src_record ë””ë ‰í† ë¦¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± íŒŒì¼ ëª©ë¡ì„ ì¡°íšŒ
    - ê¸°ì¡´ src_record ì§ì ‘ í•˜ìœ„ íŒŒì¼ë“¤
    - ì¼ìë³„ í´ë”(YYYY-MM-DD) ë‚´ì˜ íŒŒì¼ë“¤
    """
    try:
        if not os.path.exists(AUDIO_DIRECTORY):
            return {
                "status": "error",
                "message": f"ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬({AUDIO_DIRECTORY})ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "files": [],
                "daily_files": {}
            }
        
        # ê¸°ì¡´ src_record ì§ì ‘ í•˜ìœ„ ìŒì„± íŒŒì¼ë“¤ ê²€ìƒ‰
        audio_files = []
        daily_files = {}
        
        for item in os.listdir(AUDIO_DIRECTORY):
            item_path = os.path.join(AUDIO_DIRECTORY, item)
            logger.info(f"Processing item: {item}, path: {item_path}")
            
            # íŒŒì¼ì¸ ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
            if os.path.isfile(item_path):
                file_extension = os.path.splitext(item)[1].lower()
                if file_extension in SUPPORTED_AUDIO_EXTENSIONS:
                    # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                    file_stat = os.stat(item_path)
                    file_info = {
                        "filename": item,
                        "path": item,  # ê¸°ì¡´ íŒŒì¼ì€ íŒŒì¼ëª…ë§Œ
                        "size": file_stat.st_size,
                        "modified": datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                        "extension": file_extension,
                        "location": "root"  # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ í‘œì‹œ
                    }
                    audio_files.append(file_info)
            
            # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° (ì¼ìë³„ í´ë” í™•ì¸)
            elif os.path.isdir(item_path):
                logger.info(f"Found directory: {item}")
                # YYYY-MM-DD í˜•ì‹ì¸ì§€ í™•ì¸
                try:
                    # ë‚ ì§œ í˜•ì‹ ê²€ì¦
                    datetime.strptime(item, '%Y-%m-%d')
                    logger.info(f"Valid date format: {item}")
                    
                    # ì¼ìë³„ í´ë” ë‚´ ìŒì„± íŒŒì¼ë“¤ ê²€ìƒ‰
                    daily_audio_files = []
                    for daily_filename in os.listdir(item_path):
                        daily_file_path = os.path.join(item_path, daily_filename)
                        
                        if os.path.isfile(daily_file_path):
                            file_extension = os.path.splitext(daily_filename)[1].lower()
                            if file_extension in SUPPORTED_AUDIO_EXTENSIONS:
                                # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                                file_stat = os.stat(daily_file_path)
                                file_info = {
                                    "filename": daily_filename,
                                    "path": f"{item}/{daily_filename}",  # ë‚ ì§œí´ë”/íŒŒì¼ëª…
                                    "size": file_stat.st_size,
                                    "modified": datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                                    "extension": file_extension,
                                    "location": item  # ë‚ ì§œ í´ë”ëª…
                                }
                                daily_audio_files.append(file_info)
                    
                    # í´ë”ê°€ ì¡´ì¬í•˜ë©´ ìŒì„± íŒŒì¼ì´ ì—†ì–´ë„ daily_filesì— í¬í•¨ (ëŒ€ì‹œë³´ë“œ í•„í„°ë§ìš©)
                    daily_files[item] = daily_audio_files
                    logger.info(f"Added folder to daily_files: {item} with {len(daily_audio_files)} files")
                        
                except ValueError:
                    # ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹Œ ë””ë ‰í† ë¦¬ëŠ” ë¬´ì‹œ
                    continue
        
        # ì „ì²´ íŒŒì¼ ìˆ˜ ê³„ì‚°
        total_files = len(audio_files) + sum(len(files) for files in daily_files.values())
        
        # íŒŒì¼ëª…ìœ¼ë¡œ ì •ë ¬
        audio_files.sort(key=lambda x: x['filename'])
        for date_folder in daily_files:
            daily_files[date_folder].sort(key=lambda x: x['filename'])
        
        logger.info(f"ë°œê²¬ëœ ìŒì„± íŒŒì¼ ìˆ˜: ë£¨íŠ¸ {len(audio_files)}ê°œ, ì¼ìë³„ {sum(len(files) for files in daily_files.values())}ê°œ (ì´ {total_files}ê°œ)")
        
        return {
            "status": "success",
            "message": f"{total_files}ê°œì˜ ìŒì„± íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.",
            "files": audio_files,  # ê¸°ì¡´ ë£¨íŠ¸ íŒŒì¼ë“¤
            "daily_files": daily_files,  # ì¼ìë³„ í´ë”ì˜ íŒŒì¼ë“¤
            "directory": AUDIO_DIRECTORY,
            "today_folder": datetime.now().strftime('%Y-%m-%d')  # ì˜¤ëŠ˜ ë‚ ì§œ í´ë”ëª…
        }
        
    except Exception as e:
        logger.error(f"ìŒì„± íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "message": f"ìŒì„± íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "files": [],
            "daily_files": {}
        }

@app.get("/api/register-logs")
async def get_register_logs(
    limit: int = 50, 
    offset: int = 0,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """ERP ë“±ë¡ ë¡œê·¸ ëª©ë¡ ì¡°íšŒ"""
    # Supabaseê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ëª©ë¡ ë°˜í™˜
    if not supabase_mgr:
        logger.warning("âš ï¸ Supabase ì—°ê²° ì—†ìŒ. ë¹ˆ ë“±ë¡ ë¡œê·¸ ëª©ë¡ ë°˜í™˜")
        return {
            "status": "success",
            "message": "Supabase ì—°ê²° ì—†ìŒ - ë¹ˆ ëª©ë¡",
            "register_logs": [],
            "total": 0,
            "note": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ í•„ìš”í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤."
        }
    
    try:
        register_logs = supabase_mgr.get_erp_register_logs(limit=limit, offset=offset)
        return {
            "status": "success",
            "register_logs": register_logs,
            "total": len(register_logs)
        }
    except Exception as e:
        logger.error(f"ë“±ë¡ ë¡œê·¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë“±ë¡ ë¡œê·¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ë””ë ‰í† ë¦¬ë³„ íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ê´€ë ¨ API

@app.get("/api/directory-summary")
async def get_directory_summary(folder: str = None, supabase_mgr=Depends(get_supabase_manager_dep)):
    """ë””ë ‰í† ë¦¬ë³„ ì²˜ë¦¬ í˜„í™© ìš”ì•½ ì¡°íšŒ"""
    # Supabaseê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ìš”ì•½ ë°˜í™˜
    if not supabase_mgr:
        logger.warning("âš ï¸ Supabase ì—°ê²° ì—†ìŒ. ë¹ˆ ë””ë ‰í† ë¦¬ ìš”ì•½ ë°˜í™˜")
        return {
            "status": "success",
            "message": "Supabase ì—°ê²° ì—†ìŒ - ë¹ˆ ìš”ì•½",
            "summary": [],
            "total_directories": 0,
            "folder_filter": folder,
            "note": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ í•„ìš”í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤."
        }
    
    try:
        summary = supabase_mgr.get_directory_processing_summary(folder=folder)
        return {
            "status": "success",
            "summary": summary,
            "total_directories": len(summary),
            "folder_filter": folder
        }
    except Exception as e:
        logger.error(f"ë””ë ‰í† ë¦¬ë³„ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë””ë ‰í† ë¦¬ë³„ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/file-processing-status")
async def get_file_processing_status(
    directory: str = None,
    limit: int = 200,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ (ë””ë ‰í† ë¦¬ë³„ í•„í„°ë§ ì§€ì›)"""
    # Supabaseê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ëª©ë¡ ë°˜í™˜
    if not supabase_mgr:
        logger.warning("âš ï¸ Supabase ì—°ê²° ì—†ìŒ. ë¹ˆ íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ëª©ë¡ ë°˜í™˜")
        return {
            "status": "success",
            "message": "Supabase ì—°ê²° ì—†ìŒ - ë¹ˆ ëª©ë¡",
            "files": [],
            "total": 0,
            "directory": directory if directory else "ì „ì²´",
            "note": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ í•„ìš”í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤."
        }
    
    try:
        if directory:
            files = supabase_mgr.get_file_processing_status_by_directory(directory=directory, limit=limit)
        else:
            files = supabase_mgr.get_file_processing_status(limit=limit)
        
        return {
            "status": "success",
            "files": files,
            "total": len(files),
            "directory": directory if directory else "ì „ì²´"
        }
    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/check-file-processed")
async def check_file_processed(
    file_path: str,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """íŠ¹ì • íŒŒì¼ì˜ ì²˜ë¦¬ ì—¬ë¶€ í™•ì¸"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        result = supabase_mgr.check_file_processed(file_path)
        return {
            "status": "success",
            **result
        }
    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ ({file_path}): {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/processing-summary-enhanced")
async def get_processing_summary_enhanced(supabase_mgr=Depends(get_supabase_manager_dep)):
    """í–¥ìƒëœ ì „ì²´ ì²˜ë¦¬ ìƒíƒœ ìš”ì•½ (ë””ë ‰í† ë¦¬ë³„ í¬í•¨)"""
    # Supabaseê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ìš”ì•½ ë°˜í™˜
    if not supabase_mgr:
        logger.warning("âš ï¸ Supabase ì—°ê²° ì—†ìŒ. ê¸°ë³¸ ì²˜ë¦¬ ìš”ì•½ ë°˜í™˜")
        return {
            "status": "success",
            "message": "Supabase ì—°ê²° ì—†ìŒ - ê¸°ë³¸ ìš”ì•½",
            "overall_summary": {
                "total_files": 0,
                "processed_files": 0,
                "success_rate": 0.0,
                "avg_processing_time": 0.0
            },
            "directory_summaries": [],
            "recent_activity": [],
            "note": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ í•„ìš”í•œ ìƒì„¸ ì •ë³´ì…ë‹ˆë‹¤."
        }
    
    try:
        summary = supabase_mgr.get_processing_summary_enhanced()
        return {
            "status": "success",
            **summary
        }
    except Exception as e:
        logger.error(f"í–¥ìƒëœ ì²˜ë¦¬ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í–¥ìƒëœ ì²˜ë¦¬ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/update-directory-view")
async def update_directory_view(supabase_mgr=Depends(get_supabase_manager_dep)):
    """ë””ë ‰í† ë¦¬ë³„ ì²˜ë¦¬ í˜„í™© ë·°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        success = supabase_mgr.update_directory_view()
        if success:
            return {
                "status": "success",
                "message": "directory_processing_summary ë·°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"
            }
        else:
            raise HTTPException(status_code=500, detail="ë·° ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"ë·° ì—…ë°ì´íŠ¸ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë·° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")

@app.post("/api/ensure-daily-folder")
async def ensure_daily_folder():
    """
    ìˆ˜ë™ìœ¼ë¡œ ì˜¤ëŠ˜ ë‚ ì§œ í´ë” ìƒì„±
    ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ë³„ê°œë¡œ í•„ìš”ì‹œ ìˆ˜ë™ìœ¼ë¡œ í´ë”ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        today = datetime.now()
        daily_path = ensure_today_folder_exists()
        
        if daily_path:
            return {
                "success": True,
                "message": "ì¼ë³„ í´ë” ìƒì„± ì™„ë£Œ",
                "path": daily_path,
                "date": today.strftime('%Y-%m-%d'),
                "created_at": today.isoformat()
            }
        else:
            raise HTTPException(status_code=500, detail="í´ë” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
            
    except Exception as e:
        logger.error(f"ìˆ˜ë™ í´ë” ìƒì„± API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í´ë” ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.get("/api/check-daily-folders")
async def check_daily_folders():
    """
    í˜„ì¬ ìƒì„±ëœ ì¼ë³„ í´ë”ë“¤ì˜ ëª©ë¡ì„ í™•ì¸
    """
    try:
        if not os.path.exists(AUDIO_DIRECTORY):
            return {
                "success": True,
                "folders": [],
                "total_count": 0,
                "message": "src_record ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
            }
        
        # YYYY-MM-DD í˜•ì‹ì˜ í´ë”ë“¤ë§Œ í•„í„°ë§
        all_items = os.listdir(AUDIO_DIRECTORY)
        date_folders = []
        
        for item in all_items:
            item_path = os.path.join(AUDIO_DIRECTORY, item)
            if os.path.isdir(item_path):
                # YYYY-MM-DD í˜•ì‹ ê²€ì¦
                try:
                    datetime.strptime(item, '%Y-%m-%d')
                    date_folders.append(item)
                except ValueError:
                    continue  # ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹Œ í´ë”ëŠ” ì œì™¸
        
        date_folders.sort(reverse=True)  # ìµœì‹  ë‚ ì§œë¶€í„° ì •ë ¬
        
        return {
            "success": True,
            "folders": date_folders,
            "total_count": len(date_folders),
            "latest_folder": date_folders[0] if date_folders else None,
            "today_exists": datetime.now().strftime('%Y-%m-%d') in date_folders
        }
        
    except Exception as e:
        logger.error(f"ì¼ë³„ í´ë” í™•ì¸ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í´ë” í™•ì¸ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/environment-status")
async def get_environment_status():
    """í™˜ê²½ë³€ìˆ˜ ì„¤ì • ìƒíƒœ í™•ì¸"""
    env_status = {}
    
    # OpenAI API Key í™•ì¸
    openai_key = os.getenv('OPENAI_API_KEY')
    env_status['OPENAI_API_KEY'] = bool(openai_key and openai_key not in ['your_openai_api_key_here', ''])
    
    # Supabase ì„¤ì • í™•ì¸
    supabase_url = os.getenv('SUPABASE_URL')
    supabase_key = os.getenv('SUPABASE_ANON_KEY')
    env_status['SUPABASE_URL'] = bool(supabase_url and supabase_url not in ['your_supabase_url_here', ''])
    env_status['SUPABASE_ANON_KEY'] = bool(supabase_key and supabase_key not in ['your_supabase_anon_key_here', ''])
    
    # HuggingFace Token í™•ì¸
    hf_token = os.getenv('HUGGINGFACE_HUB_TOKEN')
    env_status['HUGGINGFACE_HUB_TOKEN'] = bool(hf_token and hf_token not in ['your_huggingface_token_here', ''])
    
    return {
        "status": "success",
        "environment_variables": env_status,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/model-status")
async def get_model_status():
    """ëª¨ë¸ ë¡œë”© ìƒíƒœ í™•ì¸"""
    try:
        model_status = {
            "whisper_base_loaded": whisper_model is not None,
            "cached_models": list(cached_whisper_models.keys()),
            "erp_extractor_loaded": erp_extractor is not None,
            "supabase_connected": supabase_manager is not None
        }
        
        # ìºì‹œëœ ëª¨ë¸ë“¤ì˜ ìƒì„¸ ì •ë³´
        model_details = {}
        for model_name, model in cached_whisper_models.items():
            model_details[model_name] = {
                "loaded": model is not None,
                "type": str(type(model).__name__) if model else None
            }
        
        return {
            "status": "success",
            "model_status": model_status,
            "model_details": model_details,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "status": "error",
            "message": f"ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

@app.post("/api/clear-whisper-cache")
async def clear_whisper_cache():
    """ì†ìƒëœ Whisper ëª¨ë¸ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"""
    try:
        # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
        clear_model_cache()
        
        # íŒŒì¼ ìºì‹œ ì •ë¦¬
        success, cleared_paths = clear_whisper_file_cache()
        
        if success:
            return {
                "status": "success",
                "message": "Whisper ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "cleared_paths": cleared_paths,
                "action_required": "API ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ê±°ë‚˜ ìƒˆ ëª¨ë¸ì„ ë¡œë”©í•´ì£¼ì„¸ìš”.",
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "status": "warning",
                "message": "ì •ë¦¬í•  ìºì‹œ íŒŒì¼ì´ ì—†ê±°ë‚˜ ì¼ë¶€ ì •ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "cleared_paths": cleared_paths,
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"ìºì‹œ ì •ë¦¬ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/reload-base-model")
async def reload_base_model():
    """ê¸°ë³¸ Whisper ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë”©í•©ë‹ˆë‹¤"""
    global whisper_model
    
    try:
        logger.info("ê¸°ë³¸ Whisper ëª¨ë¸ ì¬ë¡œë”© ì‹œì‘...")
        
        # ê¸°ì¡´ ëª¨ë¸ ì •ë¦¬
        if "base" in cached_whisper_models:
            del cached_whisper_models["base"]
        
        # ìƒˆë¡œ ë¡œë”©
        import time
        start_time = time.time()
        whisper_model = whisper.load_model("base")
        loading_time = time.time() - start_time
        
        # ìºì‹œì— ì €ì¥
        cached_whisper_models["base"] = whisper_model
        
        logger.info(f"ê¸°ë³¸ Whisper ëª¨ë¸ ì¬ë¡œë”© ì™„ë£Œ (ì†Œìš”ì‹œê°„: {loading_time:.2f}ì´ˆ)")
        
        return {
            "status": "success",
            "message": "ê¸°ë³¸ Whisper ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì¬ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "loading_time": round(loading_time, 2),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ì¬ë¡œë”© ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ì¬ë¡œë”© ì‹¤íŒ¨: {str(e)}")

# ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ì´ˆê¸°í™”
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    global scheduler
    logger.info("API ì„œë²„ ì‹œì‘ ì¤‘...")
    
    # FFmpeg ê²½ë¡œ ì„¤ì • (Windows winget ì„¤ì¹˜)
    try:
        import os
        ffmpeg_path = r"C:\Users\bangm\AppData\Local\Microsoft\WinGet\Packages\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\ffmpeg-7.1.1-full_build\bin"
        if os.path.exists(ffmpeg_path):
            current_path = os.environ.get('PATH', '')
            if ffmpeg_path not in current_path:
                os.environ['PATH'] = current_path + os.pathsep + ffmpeg_path
                logger.info(f"FFmpeg ê²½ë¡œ ì¶”ê°€ë¨: {ffmpeg_path}")
            else:
                logger.info("FFmpeg ê²½ë¡œê°€ ì´ë¯¸ PATHì— ìˆìŠµë‹ˆë‹¤.")
        else:
            logger.warning(f"FFmpeg ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ffmpeg_path}")
    except Exception as e:
        logger.warning(f"FFmpeg ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    try:
        # ëª¨ë¸ ì´ˆê¸°í™”
        initialize_models()
        
        # ì¼ìë³„ í´ë” ìƒì„±
        daily_path = create_daily_directory()
        if daily_path:
            logger.info(f"ì¼ìë³„ í´ë” ì„¤ì • ì™„ë£Œ: {daily_path}")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ì˜¤ë¥˜ê°€ ìˆì–´ë„ API ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰)
        if SCHEDULER_AVAILABLE:
            try:
                scheduler = BackgroundScheduler()
                scheduler.add_job(
                    scheduled_daily_folder_creation,
                    CronTrigger(hour=0, minute=0),  # ë§¤ì¼ 0ì‹œ ì‹¤í–‰
                    id='daily_folder_creation',
                    name='ì¼ë³„ í´ë” ìë™ ìƒì„±'
                )
                scheduler.start()
                logger.info("âœ… ì¼ë³„ í´ë” ìƒì„± ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ (ë§¤ì¼ 0ì‹œ ì‹¤í–‰)")
            except ImportError as e:
                logger.warning(f"âš ï¸ APScheduler íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
                logger.warning("âš ï¸ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install APScheduler>=3.10.0")
            except Exception as e:
                logger.error(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨ (API ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰): {e}")
        else:
            logger.warning("âš ï¸ APSchedulerê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì¼ë³„ í´ë” ìƒì„± ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        
        logger.info("API ì„œë²„ ì‹œì‘ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"API ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    global scheduler
    logger.info("API ì„œë²„ ì¢…ë£Œ ì¤‘...")
    try:
        if SCHEDULER_AVAILABLE and scheduler and scheduler.running:
            scheduler.shutdown(wait=False)
            logger.info("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì™„ë£Œ")
        logger.info("API ì„œë²„ ì¢…ë£Œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"API ì„œë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")

# STN ë„ë©”ì¸ ë°ì´í„° ì—°ë™ í—¬í¼ í•¨ìˆ˜ë“¤



def _build_enhanced_user_prompt(transcript_text: str, domain_data: dict) -> str:
    """ë„ë©”ì¸ ë°ì´í„° ê¸°ë°˜ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸"""
    hints = []
    
    if domain_data and domain_data.get('hints'):
        # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ëª‡ ê°œì”© ì„ íƒ
        hints.extend(domain_data['hints'].get('equipment', [])[:3])
        hints.extend(domain_data['hints'].get('errors', [])[:4])
        hints.extend(domain_data['hints'].get('requests', [])[:4])
    
    prompt = f"""[ëŒ€í™” ë‚´ìš©]
{transcript_text}"""
    
    if hints:
        prompt += f"""

[í‘œí˜„ íŒíŠ¸]
{chr(10).join(hints[:10])}"""  # ìµœëŒ€ 10ê°œë§Œ
    
    return prompt


if __name__ == "__main__":
    import uvicorn
    
    # ê°œë°œ ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 