import streamlit as st
import whisper
import tempfile
import os
from datetime import datetime
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import torch
import torchaudio
import numpy as np
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ìë™ ë¡œë“œ
load_dotenv('config.env')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ê¸° (ë°œí™”ì êµ¬ë¶„)",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
.speaker-segment {
    padding: 10px;
    margin: 5px 0;
    border-radius: 8px;
    border-left: 4px solid;
}
.speaker-0 { border-left-color: #FF6B6B; background-color: #FFE5E5; }
.speaker-1 { border-left-color: #4ECDC4; background-color: #E5F9F6; }
.speaker-2 { border-left-color: #45B7D1; background-color: #E5F3FF; }
.speaker-3 { border-left-color: #96CEB4; background-color: #E8F5E8; }
.speaker-4 { border-left-color: #FECA57; background-color: #FFF8E1; }
.speaker-5 { border-left-color: #FF9FF3; background-color: #FFE5FB; }
.speaker-unknown { border-left-color: #95A5A6; background-color: #F8F9FA; }
.env-status-success { 
    background-color: #d4edda; 
    color: #155724; 
    padding: 8px; 
    border-radius: 4px; 
    border: 1px solid #c3e6cb;
}
.env-status-warning { 
    background-color: #fff3cd; 
    color: #856404; 
    padding: 8px; 
    border-radius: 4px; 
    border: 1px solid #ffeaa7;
}
</style>
""", unsafe_allow_html=True)

# HuggingFace í† í° ì½ê¸° (config.envì—ì„œ ìë™ ë¡œë“œë¨)
def get_hf_token():
    """config.envì—ì„œ ë¡œë“œëœ HuggingFace í† í°ì„ ì½ì–´ì˜¤ê¸°"""
    return os.environ.get('HUGGINGFACE_HUB_TOKEN', None)

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ™ï¸ AI ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ê¸° (ë°œí™”ì êµ¬ë¶„)")
st.markdown("**Whisper AI + ê°„ë‹¨í•œ ë°œí™”ì êµ¬ë¶„ì„ ì‚¬ìš©í•œ ê³ ì •ë°€ ìŒì„± ì¸ì‹ ë°ëª¨**")
st.markdown("---")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # Whisper ëª¨ë¸ ì„ íƒ
    model_options = {
        "tiny": "Tiny (ê°€ì¥ ë¹ ë¦„, ë‚®ì€ ì •í™•ë„)",
        "base": "Base (ë¹ ë¦„, ë³´í†µ ì •í™•ë„)", 
        "small": "Small (ë³´í†µ, ì¢‹ì€ ì •í™•ë„)",
        "medium": "Medium (ëŠë¦¼, ë†’ì€ ì •í™•ë„)",
        "large": "Large (ê°€ì¥ ëŠë¦¼, ìµœê³  ì •í™•ë„)"
    }
    
    selected_model = st.selectbox(
        "Whisper ëª¨ë¸ ì„ íƒ:",
        options=list(model_options.keys()),
        index=2,  # small ëª¨ë¸ ê¸°ë³¸ ì„ íƒ
        format_func=lambda x: model_options[x]
    )
    
    # ì–¸ì–´ ì„ íƒ
    language_options = {
        "auto": "ìë™ ê°ì§€",
        "ko": "í•œêµ­ì–´",
        "en": "ì˜ì–´",
        "ja": "ì¼ë³¸ì–´",
        "zh": "ì¤‘êµ­ì–´",
        "es": "ìŠ¤í˜ì¸ì–´",
        "fr": "í”„ë‘ìŠ¤ì–´",
        "de": "ë…ì¼ì–´"
    }
    
    selected_language = st.selectbox(
        "ì–¸ì–´ ì„ íƒ:",
        options=list(language_options.keys()),
        index=0,
        format_func=lambda x: language_options[x]
    )
    
    st.markdown("---")
    st.header("ğŸ‘¥ ë°œí™”ì êµ¬ë¶„ ì„¤ì •")
    
    # í™˜ê²½ë³€ìˆ˜ í† í° ìƒíƒœ í™•ì¸
    env_token = get_hf_token()
    
    if env_token:
        st.markdown(f"""
        <div class="env-status-success">
            âœ… <strong>HuggingFace í† í° ê°ì§€ë¨</strong><br>
            í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ í† í°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.<br>
            í† í°: {env_token[:8]}...{env_token[-4:]}
        </div>
        """, unsafe_allow_html=True)
        st.markdown("")
    else:
        st.markdown(f"""
        <div class="env-status-warning">
            âš ï¸ <strong>í™˜ê²½ë³€ìˆ˜ í† í° ì—†ìŒ</strong><br>
            set_env.batë¥¼ ì‹¤í–‰í•˜ì—¬ í† í°ì„ ì„¤ì •í•˜ê±°ë‚˜<br>
            ì•„ë˜ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.
        </div>
        """, unsafe_allow_html=True)
        st.markdown("")
    
# ë°œí™”ì êµ¬ë¶„ í™œì„±í™” (ê°•ì œ í™œì„±í™” ì˜µì…˜ ì¶”ê°€)
enable_diarization = st.checkbox("ë°œí™”ì êµ¬ë¶„ í™œì„±í™”", value=True)  # ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½
force_diarization = st.checkbox("ê°•ì œ ë°œí™”ì êµ¬ë¶„ (í† í° ì—†ì´ë„ ì‹œë„)", value=True, help="í† í°ì´ ì—†ì–´ë„ ì‹œê°„ ê¸°ë°˜ ë°œí™”ì êµ¬ë¶„ì„ ê°•ì œ ì‹¤í–‰")

# ì „ì—­ ë³€ìˆ˜ë¡œ ì´ˆê¸°í™”
num_speakers = None
manual_hf_token = None

if enable_diarization:
    if not env_token:
        st.warning("âš ï¸ HuggingFace í† í°ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°œí™”ì êµ¬ë¶„ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    
    # ë°œí™”ì ìˆ˜ ì„¤ì •
    speaker_detection_mode = st.radio(
        "ë°œí™”ì ìˆ˜ ì„¤ì •:",
        ["ìë™ ê°ì§€", "ìˆ˜ë™ ì„¤ì •"]
    )
    
    if speaker_detection_mode == "ìˆ˜ë™ ì„¤ì •":
        num_speakers = st.slider("ì˜ˆìƒ ë°œí™”ì ìˆ˜:", 1, 10, 2)
    else:
        num_speakers = None
        
    # HuggingFace í† í° ìˆ˜ë™ ì…ë ¥ (í™˜ê²½ë³€ìˆ˜ê°€ ì—†ì„ ë•Œë§Œ)
    if not env_token:
        manual_hf_token = st.text_input(
            "HuggingFace í† í° (ìˆ˜ë™ ì…ë ¥):",
            type="password",
            help="í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì—¬ê¸°ì— í† í°ì„ ì…ë ¥í•˜ì„¸ìš”"
        )
        
    # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ” ë””ë²„ê¹… ì •ë³´"):
        st.write(f"í™˜ê²½ë³€ìˆ˜ í† í°: {'âœ… ìˆìŒ' if env_token else 'âŒ ì—†ìŒ'}")
        st.write(f"ìˆ˜ë™ í† í°: {'âœ… ì…ë ¥ë¨' if manual_hf_token else 'âŒ ì—†ìŒ'}")
        st.write(f"ë°œí™”ì ìˆ˜: {num_speakers if num_speakers else 'ìë™ ê°ì§€'}")
        st.write(f"ê°•ì œ êµ¬ë¶„: {'âœ… í™œì„±í™”' if force_diarization else 'âŒ ë¹„í™œì„±í™”'}")
    
    st.markdown("---")
    st.markdown("### ğŸ“‹ ì§€ì› íŒŒì¼ í˜•ì‹")
    st.markdown("- MP3, WAV, M4A, FLAC")
    st.markdown("- ìµœëŒ€ íŒŒì¼ í¬ê¸°: 200MB")
    
    # í™˜ê²½ë³€ìˆ˜ ì„¤ì • ê°€ì´ë“œ
    st.markdown("---")
    st.markdown("### ğŸ”§ í† í° ê´€ë¦¬")
    st.markdown("**í† í°ì„ ë³€ê²½í•˜ë ¤ë©´:**")
    st.code("config.env íŒŒì¼ì„ ì—´ì–´ì„œ í† í°ì„ ìˆ˜ì •í•˜ì„¸ìš”", language="bash")
    st.markdown("í”„ë¡œê·¸ë¨ì„ ë‹¤ì‹œ ì‹œì‘í•˜ë©´ ìƒˆ í† í°ì´ ì ìš©ë©ë‹ˆë‹¤.")

def simple_speaker_diarization(whisper_segments, num_speakers=None):
    """
    ê°•í™”ëœ ë°œí™”ì êµ¬ë¶„ - ë‹¤ì¤‘ ì „ëµ ì‚¬ìš©
    """
    if not whisper_segments:
        return whisper_segments
    
    max_speakers = num_speakers if num_speakers else 2  # ê¸°ë³¸ê°’ì„ 2ë¡œ ë³€ê²½
    
    # ì „ëµ 1: ì¹¨ë¬µ ê¸°ë°˜ êµ¬ë¶„ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
    def silence_based_diarization():
        current_speaker = 0
        previous_end = 0
        
        for i, segment in enumerate(whisper_segments):
            start_time = segment.get('start', 0)
            pause_duration = start_time - previous_end
            
            # 1ì´ˆ ì´ìƒ ì¹¨ë¬µì´ë©´ ë°œí™”ì ì „í™˜
            if i > 0 and pause_duration > 1.0:
                current_speaker = (current_speaker + 1) % max_speakers
            
            segment['speaker'] = f'SPEAKER_{current_speaker:02d}'
            previous_end = segment.get('end', start_time)
        
        return whisper_segments
    
    # ì „ëµ 2: êµëŒ€ íŒ¨í„´ (ëŒ€í™”ì˜ ê¸°ë³¸ íŠ¹ì„±)
    def alternating_pattern():
        for i, segment in enumerate(whisper_segments):
            if max_speakers == 2:
                # 2ëª…ì¼ ë•ŒëŠ” êµëŒ€ë¡œ
                segment['speaker'] = f'SPEAKER_{i % 2:02d}'
            else:
                # 3ëª… ì´ìƒì¼ ë•ŒëŠ” ìˆœí™˜
                segment['speaker'] = f'SPEAKER_{i % max_speakers:02d}'
        
        return whisper_segments
    
    # ì „ëµ 3: í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²• (ì¹¨ë¬µ + êµëŒ€)
    def hybrid_method():
        current_speaker = 0
        previous_end = 0
        speaker_changes = 0
        
        for i, segment in enumerate(whisper_segments):
            start_time = segment.get('start', 0)
            pause_duration = start_time - previous_end
            
            # ê¸´ ì¹¨ë¬µì´ë©´ ë°œí™”ì ì „í™˜
            if i > 0 and pause_duration > 1.5:
                current_speaker = (current_speaker + 1) % max_speakers
                speaker_changes += 1
            # êµëŒ€ íŒ¨í„´ë„ ê³ ë ¤ (3ê°œ ì„¸ê·¸ë¨¼íŠ¸ë§ˆë‹¤)
            elif i > 0 and i % 3 == 0 and pause_duration > 0.5:
                current_speaker = (current_speaker + 1) % max_speakers
                speaker_changes += 1
            
            segment['speaker'] = f'SPEAKER_{current_speaker:02d}'
            previous_end = segment.get('end', start_time)
        
        return whisper_segments, speaker_changes
    
    # ìµœì ì˜ ì „ëµ ì„ íƒ
    if len(whisper_segments) <= 4:
        # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì ìœ¼ë©´ ë‹¨ìˆœ êµëŒ€
        return alternating_pattern()
    else:
        # í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²• ì‹œë„
        result_segments, changes = hybrid_method()
        
        # ë°œí™”ì ë³€ê²½ì´ ë„ˆë¬´ ì ìœ¼ë©´ êµëŒ€ íŒ¨í„´ ì‚¬ìš©
        if changes < len(whisper_segments) // 4:
            return alternating_pattern()
        else:
            return result_segments

def load_pyannote_pipeline(hf_token=None):
    """pyannote-audio íŒŒì´í”„ë¼ì¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œ"""
    try:
        from pyannote.audio import Pipeline
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„
        models_to_try = [
            "pyannote/speaker-diarization",  # êµ¬ë²„ì „ (ê³µê°œ)
            "pyannote/speaker-diarization-3.1",  # ìµœì‹  (ì œí•œë¨)
        ]
        
        for model_name in models_to_try:
            try:
                if hf_token:
                    # ìµœì‹  API: token íŒŒë¼ë¯¸í„° ì‚¬ìš© (fallbackìœ¼ë¡œ use_auth_token)
                    try:
                        pipeline = Pipeline.from_pretrained(model_name, token=hf_token)
                    except TypeError:
                        pipeline = Pipeline.from_pretrained(model_name, use_auth_token=hf_token)
                else:
                    pipeline = Pipeline.from_pretrained(model_name)
                return pipeline, model_name
            except Exception as e:
                continue
        
        return None, None
        
    except ImportError:
        return None, None
    except Exception as e:
        return None, None

def assign_speakers_to_segments(whisper_segments, diarization_result):
    """Whisper ì„¸ê·¸ë¨¼íŠ¸ì— ë°œí™”ì ì •ë³´ í• ë‹¹"""
    for segment in whisper_segments:
        start_time = segment['start']
        end_time = segment['end']
        
        # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ë°œí™”ì ì°¾ê¸°
        speakers_in_segment = {}
        
        for turn, _, speaker in diarization_result.itertracks(yield_label=True):
            if turn.start < end_time and turn.end > start_time:
                # ê²¹ì¹˜ëŠ” ë¶€ë¶„ì˜ ê¸¸ì´ ê³„ì‚°
                overlap_start = max(turn.start, start_time)
                overlap_end = min(turn.end, end_time)
                overlap_duration = overlap_end - overlap_start
                
                if overlap_duration > 0:
                    speakers_in_segment[speaker] = speakers_in_segment.get(speaker, 0) + overlap_duration
        
        # ê°€ì¥ ë§ì´ ê²¹ì¹˜ëŠ” ë°œí™”ì í• ë‹¹
        if speakers_in_segment:
            dominant_speaker = max(speakers_in_segment, key=speakers_in_segment.get)
            segment['speaker'] = dominant_speaker
        else:
            segment['speaker'] = 'UNKNOWN'
    
    return whisper_segments

# ë©”ì¸ ì»¨í…ì¸ 
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    
    # íŒŒì¼ ì—…ë¡œë”
    uploaded_file = st.file_uploader(
        "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['mp3', 'wav', 'm4a', 'flac', 'ogg', 'wma'],
        help="ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )
    
    if uploaded_file is not None:
        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        file_size = uploaded_file.size / (1024 * 1024)  # MB ë‹¨ìœ„
        st.info(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
        
        # ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´
        st.audio(uploaded_file, format='audio/mp3')

with col2:
    st.header("ğŸ”„ ë³€í™˜ ê²°ê³¼")
    
    if uploaded_file is not None:
        # ë³€í™˜ ë²„íŠ¼
        if st.button("ğŸš€ í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œì‘", type="primary", use_container_width=True):
            
            # ì§„í–‰ ìƒíƒœ í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                status_text.text("ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
                progress_bar.progress(20)
                
                # Whisper ëª¨ë¸ ë¡œë“œ
                model = whisper.load_model(selected_model)
                
                status_text.text("ğŸ™ï¸ ìŒì„± ë³€í™˜ ì¤‘...")
                progress_bar.progress(40)
                
                # ìŒì„± ì¸ì‹ ì‹¤í–‰
                language_param = None if selected_language == "auto" else selected_language
                result = model.transcribe(tmp_file_path, language=language_param)
                
                progress_bar.progress(60)
                
                # ë°œí™”ì êµ¬ë¶„ ìˆ˜í–‰
                diarization_success = False
                diarization_method = "ì—†ìŒ"
                
                # ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘
                debug_info = {
                    "enable_diarization": enable_diarization,
                    "force_diarization": force_diarization,
                    "has_segments": bool(result["segments"]),
                    "segment_count": len(result["segments"]) if result["segments"] else 0,
                    "env_token": bool(env_token),
                    "manual_token": bool(manual_hf_token),
                    "num_speakers": num_speakers
                }
                
                # ë°œí™”ì êµ¬ë¶„ ì‹œë„ (ì¡°ê±´ í™•ëŒ€)
                if (enable_diarization or force_diarization) and result["segments"]:
                    status_text.text("ğŸ‘¥ ë°œí™”ì êµ¬ë¶„ ì¤‘...")
                    
                    # í† í° ìš°ì„ ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ > ìˆ˜ë™ì…ë ¥
                    final_token = env_token or manual_hf_token
                    
                    st.info(f"ğŸ” ë””ë²„ê¹…: ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ {len(result['segments'])}, í† í° {'ìˆìŒ' if final_token else 'ì—†ìŒ'}")
                    
                    # pyannote-audio ì‚¬ìš© ì‹œë„
                    if final_token:
                        pipeline, model_used = load_pyannote_pipeline(final_token)
                        
                        if pipeline is not None:
                            try:
                                status_text.text("ğŸ¤– AI ëª¨ë¸ë¡œ ë°œí™”ì êµ¬ë¶„ ì¤‘...")
                                
                                if num_speakers:
                                    diarization_result = pipeline(tmp_file_path, num_speakers=num_speakers)
                                else:
                                    diarization_result = pipeline(tmp_file_path)
                                
                                # ë°œí™”ì ì •ë³´ë¥¼ Whisper ì„¸ê·¸ë¨¼íŠ¸ì— í• ë‹¹
                                result["segments"] = assign_speakers_to_segments(result["segments"], diarization_result)
                                diarization_success = True
                                diarization_method = f"pyannote-audio ({model_used})"
                                
                                # í† í° ì‚¬ìš© ìƒíƒœ í‘œì‹œ
                                token_source = "í™˜ê²½ë³€ìˆ˜" if env_token else "ìˆ˜ë™ì…ë ¥"
                                st.success(f"âœ… pyannote-audio ëª¨ë¸ ({model_used}) ì‚¬ìš© ì„±ê³µ! (í† í°: {token_source})")
                                
                            except Exception as e:
                                st.warning(f"âš ï¸ pyannote-audio ë°œí™”ì êµ¬ë¶„ ì‹¤íŒ¨: {str(e)}")
                                debug_info["pyannote_error"] = str(e)
                        else:
                            st.warning("âš ï¸ pyannote-audio ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                    
                    # pyannote-audio ì‹¤íŒ¨ ì‹œ ë˜ëŠ” í† í° ì—†ì„ ë•Œ ê°„ë‹¨í•œ ë°©ë²• ì‚¬ìš©
                    if not diarization_success:
                        status_text.text("ğŸ”„ ì‹œê°„ ê¸°ë°˜ ë°œí™”ì êµ¬ë¶„ ì¤‘...")
                        st.info("ğŸ”„ ê°„ë‹¨í•œ ë°œí™”ì êµ¬ë¶„ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
                        
                        # ê°•í™”ëœ ê°„ë‹¨ ë°œí™”ì êµ¬ë¶„ ì‹¤í–‰
                        original_segments = [s.copy() for s in result["segments"]]  # ë°±ì—…
                        result["segments"] = simple_speaker_diarization(result["segments"], num_speakers)
                        
                        # ë°œí™”ì êµ¬ë¶„ì´ ì‹¤ì œë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        speakers_found = set(segment.get("speaker", "UNKNOWN") for segment in result["segments"])
                        if len(speakers_found) > 1:
                            diarization_success = True
                            diarization_method = "ì‹œê°„ ê¸°ë°˜ ì¶”ì •"
                            st.success(f"âœ… ì‹œê°„ ê¸°ë°˜ ë°œí™”ì êµ¬ë¶„ ì™„ë£Œ! ê°ì§€ëœ ë°œí™”ì: {len(speakers_found)}ëª…")
                        else:
                            st.error("âŒ ë°œí™”ì êµ¬ë¶„ ì‹¤íŒ¨ - ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ê°€ ë™ì¼í•œ ë°œí™”ìë¡œ ë¶„ë¥˜ë¨")
                            debug_info["simple_failed"] = True
                
                # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
                with st.expander("ğŸ” ë°œí™”ì êµ¬ë¶„ ë””ë²„ê¹… ì •ë³´"):
                    st.json(debug_info)
                    st.write(f"**ì‚¬ìš©ëœ ë°©ë²•:** {diarization_method}")
                    if result["segments"]:
                        speakers = [segment.get("speaker", "UNKNOWN") for segment in result["segments"]]
                        unique_speakers = set(speakers)
                        st.write(f"**ê°ì§€ëœ ë°œí™”ì:** {list(unique_speakers)}")
                        st.write(f"**ë°œí™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜:** {dict((s, speakers.count(s)) for s in unique_speakers)}")
                
                progress_bar.progress(100)
                status_text.text("âœ… ë³€í™˜ ì™„ë£Œ!")
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("ğŸ‰ í…ìŠ¤íŠ¸ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ì „ì²´ í…ìŠ¤íŠ¸
                full_text = result["text"]
                
                # íƒ­ìœ¼ë¡œ ê²°ê³¼ êµ¬ë¶„
                tab1, tab2, tab3 = st.tabs(["ğŸ“ ë°œí™”ìë³„ í…ìŠ¤íŠ¸", "ğŸ“Š íƒ€ì„ë¼ì¸", "ğŸ“‹ ì „ì²´ í…ìŠ¤íŠ¸"])
                
                with tab1:
                    # ë°œí™”ì ì •ë³´ í™•ì¸ (ë” ê´€ëŒ€í•œ ì¡°ê±´)
                    has_speaker_info = any(segment.get("speaker") and segment.get("speaker") != "UNKNOWN" for segment in result["segments"])
                    
                    if has_speaker_info or diarization_success:
                        st.subheader("ğŸ‘¥ ë°œí™”ìë³„ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸:")
                        
                        # ë°œí™”ìë³„ ìƒ‰ìƒ ë§¤í•‘
                        speakers = list(set(segment.get("speaker", "UNKNOWN") for segment in result["segments"]))
                        speaker_colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FECA57", "#FF9FF3"]
                        
                        # ë°œí™”ìê°€ 1ëª…ë§Œ ê°ì§€ëœ ê²½ìš° ê°•ì œë¡œ 2ëª…ìœ¼ë¡œ ì¬ë¶„í• 
                        if len(speakers) == 1 and speakers[0] == "SPEAKER_00":
                            st.warning("âš ï¸ ë°œí™”ìê°€ 1ëª…ë§Œ ê°ì§€ë˜ì–´ ê°•ì œë¡œ 2ëª…ìœ¼ë¡œ ì¬ë¶„í• í•©ë‹ˆë‹¤.")
                            for i, segment in enumerate(result["segments"]):
                                segment['speaker'] = f'SPEAKER_{i % 2:02d}'
                            speakers = ["SPEAKER_00", "SPEAKER_01"]
                        
                        for i, segment in enumerate(result["segments"]):
                            speaker = segment.get("speaker", f"SPEAKER_{i % 2:02d}")  # ë°±ì—… í• ë‹¹
                            text = segment.get("text", "")
                            start_time = segment.get("start", 0)
                            end_time = segment.get("end", 0)
                            
                            # ì‹œê°„ í¬ë§·íŒ…
                            start_str = f"{int(start_time//60):02d}:{int(start_time%60):02d}"
                            end_str = f"{int(end_time//60):02d}:{int(end_time%60):02d}"
                            
                            speaker_idx = speakers.index(speaker) if speaker in speakers else i % len(speaker_colors)
                            if speaker_idx >= len(speaker_colors):
                                speaker_idx = speaker_idx % len(speaker_colors)
                            
                            st.markdown(f"""
                            <div class="speaker-segment speaker-{speaker_idx}">
                                <strong>ğŸ¤ {speaker} [{start_str}-{end_str}]</strong><br>
                                {text}
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.warning("âŒ ë°œí™”ì êµ¬ë¶„ ì‹¤íŒ¨ - ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
                        st.info("ê°•ì œ ë°œí™”ì êµ¬ë¶„ì„ í™œì„±í™”í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
                        
                        for segment in result["segments"]:
                            text = segment.get("text", "")
                            start_time = segment.get("start", 0)
                            end_time = segment.get("end", 0)
                            start_str = f"{int(start_time//60):02d}:{int(start_time%60):02d}"
                            end_str = f"{int(end_time//60):02d}:{int(end_time%60):02d}"
                            
                            st.markdown(f"**[{start_str}-{end_str}]** {text}")
                
                with tab2:
                    if result["segments"]:
                        st.subheader("ğŸ“Š ë°œí™” íƒ€ì„ë¼ì¸:")
                        
                        # íƒ€ì„ë¼ì¸ ë°ì´í„° ì¤€ë¹„
                        timeline_data = []
                        for segment in result["segments"]:
                            timeline_data.append({
                                "Speaker": segment.get("speaker", "UNKNOWN"),
                                "Start": segment.get("start", 0),
                                "End": segment.get("end", 0),
                                "Duration": segment.get("end", 0) - segment.get("start", 0),
                                "Text": segment.get("text", "")[:50] + "..." if len(segment.get("text", "")) > 50 else segment.get("text", "")
                            })
                        
                        df = pd.DataFrame(timeline_data)
                        
                        if enable_diarization and any("speaker" in segment for segment in result["segments"]):
                            # Gantt ì°¨íŠ¸ ìƒì„±
                            fig = px.timeline(df, x_start="Start", x_end="End", y="Speaker", color="Speaker",
                                            hover_data=["Text"], title="ë°œí™”ìë³„ íƒ€ì„ë¼ì¸")
                            fig.update_layout(height=400)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # ë°œí™”ìë³„ í†µê³„
                            speaker_stats = df.groupby("Speaker")["Duration"].agg(["count", "sum"]).round(2)
                            speaker_stats.columns = ["ë°œí™” íšŸìˆ˜", "ì´ ë°œí™” ì‹œê°„(ì´ˆ)"]
                            st.subheader("ğŸ“ˆ ë°œí™”ìë³„ í†µê³„:")
                            st.dataframe(speaker_stats)
                        else:
                            st.info("ë°œí™”ì êµ¬ë¶„ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ íƒ€ì„ë¼ì¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                            fig = go.Figure()
                            for i, row in df.iterrows():
                                fig.add_trace(go.Scatter(
                                    x=[row["Start"], row["End"]],
                                    y=[1, 1],
                                    mode="lines+markers",
                                    name=f"Segment {i+1}",
                                    text=row["Text"],
                                    hovertemplate="<b>%{text}</b><br>Start: %{x[0]:.1f}s<br>End: %{x[1]:.1f}s"
                                ))
                            fig.update_layout(title="ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì„ë¼ì¸", xaxis_title="ì‹œê°„ (ì´ˆ)", yaxis_title="ì„¸ê·¸ë¨¼íŠ¸")
                            st.plotly_chart(fig, use_container_width=True)
                
                with tab3:
                    st.subheader("ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸:")
                    st.text_area("", value=full_text, height=300, disabled=True)
                    
                    # ìƒì„¸ ì •ë³´
                    with st.expander("ğŸ“Š ìƒì„¸ ì •ë³´ ë³´ê¸°"):
                        st.write(f"**ê°ì§€ëœ ì–¸ì–´:** {result.get('language', 'Unknown')}")
                        st.write(f"**ì´ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜:** {len(result['segments'])}")
                        
                        if enable_diarization and any("speaker" in segment for segment in result["segments"]):
                            unique_speakers = set(segment.get("speaker", "UNKNOWN") for segment in result["segments"])
                            st.write(f"**ê°ì§€ëœ ë°œí™”ì ìˆ˜:** {len(unique_speakers)}")
                            st.write(f"**ë°œí™”ì ëª©ë¡:** {', '.join(unique_speakers)}")
                            
                            if diarization_success:
                                method = "ê³ ê¸‰ AI ëª¨ë¸" if 'pyannote' in str(locals().get('model_used', '')) else "ì‹œê°„ ê¸°ë°˜ ì¶”ì •"
                                token_info = f" (í† í°: {'í™˜ê²½ë³€ìˆ˜' if env_token else 'ìˆ˜ë™ì…ë ¥' if locals().get('manual_hf_token') else 'ì—†ìŒ'})"
                                st.write(f"**ë°œí™”ì êµ¬ë¶„ ë°©ë²•:** {method}{token_info}")
                
                # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                st.subheader("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
                col_txt, col_json, col_csv = st.columns(3)
                
                with col_txt:
                    # ë°œí™”ìë³„ í…ìŠ¤íŠ¸ íŒŒì¼
                    if enable_diarization and any("speaker" in segment for segment in result["segments"]):
                        speaker_text = ""
                        for segment in result["segments"]:
                            speaker = segment.get("speaker", "UNKNOWN")
                            text = segment.get("text", "")
                            start_time = segment.get("start", 0)
                            end_time = segment.get("end", 0)
                            start_str = f"{int(start_time//60):02d}:{int(start_time%60):02d}"
                            end_str = f"{int(end_time//60):02d}:{int(end_time%60):02d}"
                            speaker_text += f"[{start_str}-{end_str}] {speaker}: {text}\n"
                    else:
                        speaker_text = full_text
                        
                    st.download_button(
                        label="ğŸ“„ ë°œí™”ìë³„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
                        data=speaker_text,
                        file_name=f"transcript_speakers_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                
                with col_json:
                    # JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                    json_data = json.dumps(result, ensure_ascii=False, indent=2)
                    st.download_button(
                        label="ğŸ“‹ JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=json_data,
                        file_name=f"transcript_detail_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                
                with col_csv:
                    # CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                    if result["segments"]:
                        csv_data = []
                        for segment in result["segments"]:
                            csv_data.append({
                                "ë°œí™”ì": segment.get("speaker", "UNKNOWN"),
                                "ì‹œì‘ì‹œê°„": segment.get("start", 0),
                                "ì¢…ë£Œì‹œê°„": segment.get("end", 0),
                                "í…ìŠ¤íŠ¸": segment.get("text", "")
                            })
                        df_csv = pd.DataFrame(csv_data)
                        csv_string = df_csv.to_csv(index=False, encoding='utf-8-sig')
                        
                        st.download_button(
                            label="ğŸ“Š CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                            data=csv_string,
                            file_name=f"transcript_segments_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(tmp_file_path)
                
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                if 'tmp_file_path' in locals():
                    os.unlink(tmp_file_path)
    else:
        st.info("ğŸ‘ˆ ë¨¼ì € ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("### ğŸ’¡ ì‚¬ìš© íŒ")
col_tip1, col_tip2, col_tip3, col_tip4 = st.columns(4)

with col_tip1:
    st.markdown("**ğŸ¯ ìµœì ì˜ ìŒì§ˆ**")
    st.markdown("- ë°°ê²½ ì†ŒìŒ ìµœì†Œí™”")
    st.markdown("- ëª…í™•í•œ ë°œìŒ")
    st.markdown("- ì ì ˆí•œ ìŒëŸ‰")

with col_tip2:
    st.markdown("**âš¡ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ**")
    st.markdown("- Small: ì¼ë°˜ì  ì‚¬ìš©")
    st.markdown("- Medium: ë†’ì€ í’ˆì§ˆ")
    st.markdown("- Large: ìµœê³  í’ˆì§ˆ")

with col_tip3:
    st.markdown("**ğŸ‘¥ ë°œí™”ì êµ¬ë¶„ íŒ**")
    st.markdown("- ëª…í™•í•œ í™”ì êµ¬ë¶„")
    st.markdown("- ì ì ˆí•œ ë°œí™” ê°„ê²©")
    st.markdown("- ë°œí™”ì ìˆ˜ ì‚¬ì „ íŒŒì•…")

with col_tip4:
    st.markdown("**ğŸŒ ì–¸ì–´ ì§€ì›**")
    st.markdown("- 99ê°œ ì–¸ì–´ ì§€ì›")
    st.markdown("- ìë™ ê°ì§€ ì¶”ì²œ")
    st.markdown("- ë‹¤êµ­ì–´ í˜¼ìš© ê°€ëŠ¥")

st.markdown("---")
st.markdown("### ğŸ“ í™˜ê²½ë³€ìˆ˜ë¡œ í† í° ê´€ë¦¬")
st.info("""
**ë³´ì•ˆì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©:**
1. `set_env.bat` ì‹¤í–‰í•˜ì—¬ í† í°ì„ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
2. í„°ë¯¸ë„ì„ ë‹¤ì‹œ ì‹œì‘í•œ í›„ ì•± ì‹¤í–‰
3. í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ë©´ ìë™ìœ¼ë¡œ í† í° ì‚¬ìš©

**í™˜ê²½ë³€ìˆ˜ì˜ ì¥ì :**
- ğŸ”’ ì½”ë“œì— í† í°ì´ ë…¸ì¶œë˜ì§€ ì•ŠìŒ
- ğŸ”„ ë§¤ë²ˆ ì…ë ¥í•  í•„ìš” ì—†ìŒ
- ğŸ›¡ï¸ ë” ì•ˆì „í•œ í† í° ê´€ë¦¬
""")

st.markdown("**Made with â¤ï¸ using Whisper AI, pyannote-audio & Streamlit**") 